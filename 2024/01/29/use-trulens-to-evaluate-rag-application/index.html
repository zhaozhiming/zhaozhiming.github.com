<!DOCTYPE HTML>
<html>
<head>
	<meta charset="utf-8">
    
	<title>使用 Trulens 评估 RAG 应用 - Hacker and Geeker&#39;s Way</title>
    <meta name="author" content="">
    
	<meta name="description" content="介绍使用 Trulens 如何安装使用以及其内部原理"> <!-- TODO: truncate -->
	<meta name="keywords" content="llm, rag, trulens">
	<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">

	<link href="atom.xml" rel="alternate" title="Hacker and Geeker&#39;s Way" type="application/atom+xml">
	<link href="/favicon.ico" rel="shortcut icon">
    <link href="/stylesheets/screen.css" media="screen, projection" rel="stylesheet" type="text/css">
    <link href="/stylesheets/custom.css" media="screen, projection" rel="stylesheet" type="text/css">
    <link href="/stylesheets/hljs.css" media="screen, projection" rel="stylesheet" type="text/css">

    <link href='/stylesheets/font.css?family=Slackey' rel='stylesheet' type='text/css'>
    <link href='/stylesheets/font.css?family=Fjalla+One' rel='stylesheet' type='text/css'>
    <link href='/stylesheets/font.css?family=Amethysta+One' rel='stylesheet' type='text/css'>
	  <script src="/javascripts/jquery.min.js"></script>
    <!--[if lt IE 9]><script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script><![}]-->

    <script type="text/javascript" src="/javascripts/jquery-tapir.js"></script>

    <!-- remove or comment it to disable ajaxification -->   
    <!-- <script src="/javascripts/ajaxify.js"></script> -->

    

    
	<script type="text/javascript">
		var _gaq = _gaq || [];
		_gaq.push(['_setAccount', 'UA-100485541-1']);
		_gaq.push(['_trackPageview']);

		(function() {
			var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
			ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
			var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
		})();
	</script>


<meta name="generator" content="Hexo 6.3.0"></head>


<body>
    <div id="wrapper">
    <header id="header" class="inner"><!-- for more effects see _animate.scss -->
<h1 class="animated bounceInDown">
    <div id="headerbg">
        Hacker and Geeker&#39;s Way
    </div>
</h1>
<span class="subtitle"></span>
<br>

<ul id="social-links" style="text-align:center; clear:both;">
  
  <!-- GitHub -->
  <li>
  <a target="_blank" rel="noopener" href="https://github.com/zhaozhiming" class="github" title="Github"></a>
  </li>
  
  
  
  
  <!-- Twitter -->
  <li>
  <a target="_blank" rel="noopener" href="http://www.twitter.com/kingzzm" class="twitter" title="Twitter"></a>
  </li>
  
  
  <!-- LinkedIn -->
  <li>
  <a target="_blank" rel="noopener" href="http://www.linkedin.com/in/zhaozhiming" class="linkedin" title="LinkedIn"></a>
  </li>
  
  
  
  
  
  <!-- Stackoverflow -->
  <li>
  <a target="_blank" rel="noopener" href="http://stackoverflow.com/users/1954315/zhaozhiming" class="stackoverflow" title="Stackoverflow"></a>
  </li>
  
</ul>


<!-- use full url including 'index.html' for navigation bar if you are using ajax -->
<ul id="nav">
	<li id="ajax"><a href="/index.html">Home</a></li>
	<li id="ajax"><a href="/archives/index.html">Archives</a></li>
    <li><a href="/atom.xml">RSS</a></li>
    <li><a href="/about/index.html">About</a></li>
    
    <li>
    <div id="dark">
        <form action="//www.google.com.hk/search" method="get" accept-charset="UTF-8" id="search">
            <input type="hidden" name="sitesearch" value="https://zhaozhiming.github.io" />
            <input type="text" name="q" results="0" placeholder="Search..." x-webkit-speech />
        </form>
    </div>
    </li>
        
</ul>




</header>


<div id="toload">
<!-- begin toload -->
    <div id="content">
        <div class="inner">
<article class="post">
	<h2 class="title">使用 Trulens 评估 RAG 应用</h2>
    <div class="meta">
        <div class="date">Published on: <time datetime="2024-01-29T01:47:05.000Z" itemprop="datePublished">1月 29, 2024</time>
</div>
        <div class="tags">Tags: 

<a href="/tags/llm/">llm</a> <a href="/tags/rag/">rag</a> <a href="/tags/trulens/">trulens</a>
</div>
    </div>
	<div class="entry-content"><img src="/images/post/2024/01/trulens.jpg" class="" width="400" height="300">

<p>目前基于大语言模型（LLM）的 RAG（Retrieval Augmented Generation）应用非常广泛，包括知识库问答、客服机器人、垂直领域知识检索等各个方面，虽然我们可以构建出这类应用，但是如何评估 RAG 应用的效果却是一个难题。幸运的是业界已经开始推出一些 RAG 评估工具，Trulens 就是其中的一个。本文将介绍如何使用 Trulens 这个工具来对 RAG 应用进行评估，同时介绍 Trulens 内部的实现原理，以及在探索过程中发现的一些有趣知识。</p>
<span id="more"></span>

<h2 id="Trulens-介绍"><a href="#Trulens-介绍" class="headerlink" title="Trulens 介绍"></a>Trulens 介绍</h2><p><a target="_blank" rel="noopener" href="https://www.trulens.org/">TruLens</a>是一款旨在评估和改进 LLM 应用的软件工具，它相对独立，可以集成 LangChain 或 LlamaIndex 等 LLM 开发框架。它使用反馈功能来客观地衡量 LLM 应用的质量和效果。这包括分析相关性、适用性和有害性等方面。TruLens 提供程序化反馈，支持 LLM 应用的快速迭代，这比人工反馈更快速、更可扩展。它适用于各种用途，如聊天机器人，并可以轻松集成到现有的 LLM 应用中。TruLens 是由 AI 质量软件公司 <a target="_blank" rel="noopener" href="https://truera.com/">TruEra</a> 开发的开源项目。</p>
<h2 id="Trulens-核心概念"><a href="#Trulens-核心概念" class="headerlink" title="Trulens 核心概念"></a>Trulens 核心概念</h2><p>在 Trulens 的设计中，他们优先提出了 RAG 应用的三大相关性评估：Anwer Relevance（答案相关性）、Context Relevance（上下文相关性） 和 Groundedness（基于实际情况的相关性）。</p>
<img src="/images/post/2024/01/rag_triad.jpg" class="" width="1000" height="600">

<ul>
<li>Anwer Relevance：衡量 LLM 的最终回答如何解答原始问题，确保其具有帮助性和相关性。</li>
<li>Context Relevance：评估 RAG 检索到的上下文（也就是检索到的文档）与原始问题的相关性。这一点非常重要，因为上下文构成了 LLM 答案的基础。</li>
<li>Groundedness：评估 LLM 的最终回答是否与上下文中提供的事实（检索到的文档）保持一致，确保不夸大或偏离给定的信息。</li>
</ul>
<p>这三大组成部分共同确保 LLM 的回答准确、相关且没有出现幻觉。</p>
<h2 id="结合-LlamaIndex-使用-Trulens"><a href="#结合-LlamaIndex-使用-Trulens" class="headerlink" title="结合 LlamaIndex 使用 Trulens"></a>结合 LlamaIndex 使用 Trulens</h2><p>我们将使用<a target="_blank" rel="noopener" href="https://www.llamaindex.ai/">LlamaIndex</a>这个 LLM 应用框架来实现简单的 RAG 应用，再用 Trulens 评估其效果。在 RAG 应用中，我们使用大家熟知的漫威电影<strong>复仇者联盟</strong>相关剧情来作为测试文档，通过输入相关的问题，RAG 应用检索出相关的剧情介绍并回答问题，文档内容主要从维基百科上的<a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Avenger">复仇者联盟</a>条目中获取，主要包括 4 部复仇者联盟电影的剧情信息。</p>
<p>首先我们需要安装 LlamaIndex 和 Trulens 的 Python 依赖包：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install llama-index trulens-eval</span><br></pre></td></tr></table></figure>

<p>然后使用 LlamaIndex 来创建一个简单的 RAG 功能：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> llama_index <span class="keyword">import</span> VectorStoreIndex, SimpleDirectoryReader</span><br><span class="line"></span><br><span class="line">documents = SimpleDirectoryReader(<span class="string">&quot;./data&quot;</span>).load_data()</span><br><span class="line">index = VectorStoreIndex.from_documents(documents)</span><br><span class="line">query_engine = index.as_query_engine()</span><br></pre></td></tr></table></figure>

<p>以上代码会从 <code>./data</code> 目录下读取文档，解析并将文档分块存储到向量数据库，同时创建一个向量存储索引。LlamaIndex 默认使用的 LLM 是 OpenAI 的<code>gpt3.5-turbo</code>模型，Embedding 使用的是 OpenAI 的<code>text-embedding-ada-002</code>模型。</p>
<p><code>data</code>目录是存放测试文档的地方，其目录结构如下：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">data/</span><br><span class="line">├── 复仇者联盟.txt</span><br><span class="line">├── 复仇者联盟2：奥创纪元.txt</span><br><span class="line">├── 复仇者联盟3：无限战争.txt</span><br><span class="line">└── 复仇者联盟4：终局之战.txt</span><br></pre></td></tr></table></figure>

<p>每个文档包含了该部电影的剧情信息，接下来我们使用 Trulens 来逐一创建三大相关性评估，首先是<code>Groundedness</code>评估：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> trulens_eval <span class="keyword">import</span> Feedback, TruLlama</span><br><span class="line"><span class="keyword">from</span> trulens_eval.feedback <span class="keyword">import</span> Groundedness</span><br><span class="line"><span class="keyword">from</span> trulens_eval.feedback.provider.openai <span class="keyword">import</span> OpenAI</span><br><span class="line"></span><br><span class="line">openai = OpenAI()</span><br><span class="line"></span><br><span class="line">grounded = Groundedness(groundedness_provider=openai)</span><br><span class="line">groundedness = (</span><br><span class="line">    Feedback(grounded.groundedness_measure_with_cot_reasons, name=<span class="string">&quot;Groundedness&quot;</span>)</span><br><span class="line">    .on(TruLlama.select_source_nodes().node.text)</span><br><span class="line">    .on_output()</span><br><span class="line">    .aggregate(grounded.grounded_statements_aggregator)</span><br><span class="line">)</span><br></pre></td></tr></table></figure>

<ul>
<li>使用 Trulens 提供的 Provider 类来创建一个 OpenAI Provider，在实际做评估时会使用到 OpenAI 的 LLM 来为 RAG 应用评分，更多的 Provider 类可以参考 Trulens 的文档</li>
<li>定义了一个<code>Groundedness</code>对象来集成之前的 Provider</li>
<li>定义一个<code>Feedback</code>对象来实现评估功能，这里使用构建者模式来创建<code>Feedback</code>对象</li>
<li>在<code>Feedback</code>构造器方法中，需要传入一个评估方法，我们使用<code>Groundedness</code>对象中的<code>groundedness_measure_with_cot_reasons</code>方法，表示使用思维链的方式来进行评估</li>
<li><code>Feedback</code>的<code>on</code>和<code>on_output</code> 方法是选择输入和输出，以<code>Groundedness</code>相关性评估为例，输入是检索到的文档，输出是 LLM 的最终结果</li>
<li><code>aggregate</code>方法表示评估结果的聚合方式，这里使用<code>Groundedness</code>对象中的<code>grounded_statements_aggregator</code>方法来作为评估结果的聚合方式</li>
</ul>
<p>接下来我们再创建<code>Answer Relevance</code>评估：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">qa_relevance = Feedback(</span><br><span class="line">    openai.relevance_with_cot_reasons, name=<span class="string">&quot;Answer Relevance&quot;</span></span><br><span class="line">).on_input_output()</span><br></pre></td></tr></table></figure>

<ul>
<li><code>Answer Relevance</code>比较简单，我们同样使用<code>Feedback</code>来构建评估方法</li>
<li>使用了 OpenAI Provider 的<code>relevance_with_cot_reasons</code>方法来作为评估方法，也是用思维链的方式评估</li>
<li>使用<code>on_input_output</code>传入默认的输入和输出参数，<code>Answer Relevance</code>评估的输入是原始问题，输出是 LLM 的最终结果</li>
</ul>
<p>然后再创建<code>Context Relevance</code>评估：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">qs_relevance = (</span><br><span class="line">    Feedback(openai.qs_relevance_with_cot_reasons, name=<span class="string">&quot;Context Relevance&quot;</span>)</span><br><span class="line">    .on_input()</span><br><span class="line">    .on(TruLlama.select_source_nodes().node.text)</span><br><span class="line">    .aggregate(np.mean)</span><br><span class="line">)</span><br></pre></td></tr></table></figure>

<ul>
<li><code>Context Relevance</code>我们同样使用<code>Feedback</code>来构建评估方法，使用了 OpenAI Provider 的<code>qs_relevance_with_cot_reasons</code>方法来作为评估方法，也是用思维链的方式评估</li>
<li>在输入和输出参数中，<code>Context Relevance</code>评估的输入是原始问题，输出是检索到的文档</li>
<li><code>aggregate</code>方法我们使用了<code>np.mean</code>来作为评估结果的聚合方式，这也是 Trulens 默认的聚合方式</li>
</ul>
<p>我们将这些评估方法集成到 Trulens 中：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">tru_query_engine_recorder = TruLlama(</span><br><span class="line">    query_engine,</span><br><span class="line">    app_id=<span class="string">&quot;Avengers_App&quot;</span>,</span><br><span class="line">    feedbacks=[groundedness, qa_relevance, qs_relevance],</span><br><span class="line">)</span><br></pre></td></tr></table></figure>

<ul>
<li><code>TruLlama</code>是 Trulens 集成 LlamaIndex 的类，初始化参数包括 LlamaIndex 的查询引擎<code>query_engine</code>、应用 ID<code>app_id</code>和评估方法<code>feedbacks</code>，<code>feedbacks</code>包含了之前创建的 3 种评估方法。</li>
</ul>
<p>接着我们准备好一些问题，通过<code>query_engine</code>进行检索和回答，在回答问题的过程中 Trulens 会触发评估方法并记录信息，从而收集评估结果：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">questions = [</span><br><span class="line">    <span class="string">&quot;洛基使用了哪种神秘物品试图征服地球？&quot;</span>,</span><br><span class="line">    <span class="string">&quot;奥创是由哪两位复仇者联盟成员创造的？&quot;</span>,</span><br><span class="line">    <span class="string">&quot;灭霸如何实现灭绝宇宙一半生命的计划？&quot;</span>,</span><br><span class="line">    <span class="string">&quot;复仇者联盟用什么方法来逆转灭霸的行动？&quot;</span>,</span><br><span class="line">    <span class="string">&quot;为了击败灭霸，哪位复仇者联盟成员牺牲了自己？&quot;</span>,</span><br><span class="line">]</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> tru_query_engine_recorder <span class="keyword">as</span> recording:</span><br><span class="line">    <span class="keyword">for</span> question <span class="keyword">in</span> questions:</span><br><span class="line">        query_engine.query(question)</span><br></pre></td></tr></table></figure>

<p>最后，我们打开 Trulens 的仪表盘来查看评估结果：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> trulens_eval <span class="keyword">import</span> Tru</span><br><span class="line"></span><br><span class="line">tru = Tru()</span><br><span class="line">tru.reset_database()</span><br><span class="line">tru.run_dashboard()</span><br></pre></td></tr></table></figure>

<ul>
<li>为了可以重复执行程序，这里我们使用了<code>tru.reset_database()</code>来重置数据库，清空之前收集的评估结果</li>
<li>然后我们使用<code>tru.run_dashboard()</code>来运行 Trulens 的仪表盘</li>
</ul>
<p>在浏览器中访问<code>localhost:8501</code>可以看到最终的评估结果：</p>
<img src="/images/post/2024/01/trulens-dashboard1.png" class="" width="1000" height="400">

<img src="/images/post/2024/01/trulens-dashboard2.png" class="" width="1000" height="400">

<p>有 5 个问题，因此会产生 5 条记录，在第二张图片中，选择其中一个记录，可以看到记录评估结果的详细信息，包括每个问题的<code>Answer Relevance</code>、<code>Context Relevance</code>和<code>Groundedness</code>相关性评估。</p>
<h2 id="Trulens-提示词模板"><a href="#Trulens-提示词模板" class="headerlink" title="Trulens 提示词模板"></a>Trulens 提示词模板</h2><p>在 Trulens 内部实现中，是通过提示词模板来让 LLM 生成评估结果的，我们通过 Trulens 的提示词来了解其实现原理。</p>
<h3 id="Groundedness-提示词模板"><a href="#Groundedness-提示词模板" class="headerlink" title="Groundedness 提示词模板"></a>Groundedness 提示词模板</h3><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">&quot;&quot;&quot;You are a INFORMATION OVERLAP classifier providing the overlap of information between a SOURCE and STATEMENT.</span></span><br><span class="line"><span class="string">For every sentence in the statement, please answer with this template:</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">TEMPLATE:</span></span><br><span class="line"><span class="string">Statement Sentence: &lt;Sentence&gt;,</span></span><br><span class="line"><span class="string">Supporting Evidence: &lt;Choose the exact unchanged sentences in the source that can answer the statement, if nothing matches, say NOTHING FOUND&gt;</span></span><br><span class="line"><span class="string">Score: &lt;Output a number between 0-10 where 0 is no information overlap and 10 is all information is overlapping&gt;</span></span><br><span class="line"><span class="string">Give me the INFORMATION OVERLAP of this SOURCE and STATEMENT.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">SOURCE: &#123;premise&#125;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">STATEMENT: &#123;hypothesis&#125;</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br></pre></td></tr></table></figure>

<p>提示词模板中的变量<code>premise</code>是检索到文档，<code>hypothesis</code>是 LLM 的最终回答，每个文档经过评估后生成以下 3 个结果：</p>
<ul>
<li>Statement Sentence：检索到的原始文档</li>
<li>Supporting Evidence：原始文档中与 LLM 最终回答相关的句子</li>
<li>Score：匹配度得分，范围是 0-10</li>
</ul>
<p>以这个问题为例：<code>灭霸如何实现灭绝宇宙一半生命的计划？</code>，检索到的文档有 2 个，经过 LLM 评估后的结果如下：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">Statement Sentence: 灭霸通过获取六颗无限宝石并将它们装配在无限手套上，实现了他消灭宇宙一半生命的计划。</span><br><span class="line">Supporting Evidence: 灭霸从星球Xandar获得了力量宝石——六颗无限宝石之一后，他和他的副手——厄奎斯·莫、库尔·奥比迪恩、普罗克西玛·午夜和科尔弗斯·格莱夫截击了运载阿斯加德幸存者的宇宙飞船。</span><br><span class="line">Score: 7</span><br><span class="line"></span><br><span class="line">Statement Sentence: 凭借完成的无限手套，灭霸能够利用宝石的力量，通过一次手指的轻响将宇宙中一半的生命消灭。</span><br><span class="line">Supporting Evidence: 包括巴恩斯、格鲁特、旺达、威尔逊、曼蒂斯、德拉克斯、奎尔、斯特兰奇、帕克、玛丽亚·希尔和尼克·弗瑞等，在整个宇宙中的一半生命都消散了，而最后一位在消失之前通过改装的呼叫器发出了紧急信号的是尼克·弗瑞。</span><br><span class="line">Score: 8</span><br></pre></td></tr></table></figure>

<p>Groundedness 的计分方法是这样的：平均得分是 (7+8)&#x2F;2 &#x3D; 7.5，除以 10 之后得到 0.75。</p>
<h3 id="Answer-Relevance-提示词模板"><a href="#Answer-Relevance-提示词模板" class="headerlink" title="Answer Relevance 提示词模板"></a>Answer Relevance 提示词模板</h3><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">&quot;&quot;&quot;You are a RELEVANCE grader; providing the relevance of the given RESPONSE to the given PROMPT.</span></span><br><span class="line"><span class="string">Respond only as a number from 0 to 10 where 0 is the least relevant and 10 is the most relevant.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">A few additional scoring guidelines:</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">- Long RESPONSES should score equally well as short RESPONSES.</span></span><br><span class="line"><span class="string"># 长回答与短回答的得分应该相同。</span></span><br><span class="line"><span class="string">- Answers that intentionally do not answer the question, such as &#x27;I don&#x27;t know&#x27; and model refusals, should also be counted as the most RELEVANT.</span></span><br><span class="line"><span class="string"># 故意不回答问题的答案，比如“我不知道”和模型拒绝，也应被视为最相关。</span></span><br><span class="line"><span class="string">- RESPONSE must be relevant to the entire PROMPT to get a score of 10.</span></span><br><span class="line"><span class="string"># 回答必须与整个提示相关，才能获得10分。</span></span><br><span class="line"><span class="string">- RELEVANCE score should increase as the RESPONSE provides RELEVANT context to more parts of the PROMPT.</span></span><br><span class="line"><span class="string"># 相关性分数应随着回答为提示的更多部分提供相关上下文而增加。</span></span><br><span class="line"><span class="string">- RESPONSE that is RELEVANT to none of the PROMPT should get a score of 0.</span></span><br><span class="line"><span class="string"># 对于与提示无关的回答，得分应为0。</span></span><br><span class="line"><span class="string">- RESPONSE that is RELEVANT to some of the PROMPT should get as score of 2, 3, or 4. Higher score indicates more RELEVANCE.</span></span><br><span class="line"><span class="string"># 对于与提示部分相关的回答，得分应为2、3或4。较高的得分表示更相关。</span></span><br><span class="line"><span class="string">- RESPONSE that is RELEVANT to most of the PROMPT should get a score between a 5, 6, 7 or 8. Higher score indicates more RELEVANCE.</span></span><br><span class="line"><span class="string"># 对于与提示大部分相关的回答，得分应在5、6、7或8之间。较高的得分表示更相关。</span></span><br><span class="line"><span class="string">- RESPONSE that is RELEVANT to the entire PROMPT should get a score of 9 or 10.</span></span><br><span class="line"><span class="string"># 对于与整个提示相关的回答，得分应为9或10。</span></span><br><span class="line"><span class="string">- RESPONSE that is RELEVANT and answers the entire PROMPT completely should get a score of 10.</span></span><br><span class="line"><span class="string"># 对于与整个提示完全相关且完整回答的回答，得分应为10。</span></span><br><span class="line"><span class="string">- RESPONSE that confidently FALSE should get a score of 0.</span></span><br><span class="line"><span class="string"># 对于自信地错误的回答，得分应为0。</span></span><br><span class="line"><span class="string">- RESPONSE that is only seemingly RELEVANT should get a score of 0.</span></span><br><span class="line"><span class="string"># 对于看似相关但实际上无关的回答，得分应为0。</span></span><br><span class="line"><span class="string">- Never elaborate.</span></span><br><span class="line"><span class="string"># 不要详细阐述。</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">PROMPT: &#123;prompt&#125;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">RESPONSE: &#123;response&#125;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">RELEVANCE: &quot;&quot;&quot;</span></span><br></pre></td></tr></table></figure>

<ul>
<li>模板中的<code>prompt</code>变量是原始的问题，<code>response</code>是 LLM 的最终答案</li>
<li>这是思维链的提示词模板，可以看到评分标准非常多，LLM 会根据评分标准来为两者的相关性打分</li>
</ul>
<h3 id="Context-Relevance-提示词模板"><a href="#Context-Relevance-提示词模板" class="headerlink" title="Context Relevance 提示词模板"></a>Context Relevance 提示词模板</h3><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">&quot;&quot;&quot;You are a RELEVANCE grader; providing the relevance of the given STATEMENT to the given QUESTION.</span></span><br><span class="line"><span class="string">Respond only as a number from 0 to 10 where 0 is the least relevant and 10 is the most relevant.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">A few additional scoring guidelines:</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">- Long STATEMENTS should score equally well as short STATEMENTS.</span></span><br><span class="line"><span class="string"># 长陈述与短陈述的得分应该相同。</span></span><br><span class="line"><span class="string">- RELEVANCE score should increase as the STATEMENT provides more RELEVANT context to the QUESTION.</span></span><br><span class="line"><span class="string"># 相关性分数应随着陈述为问题提供更多相关上下文而增加。</span></span><br><span class="line"><span class="string">- RELEVANCE score should increase as the STATEMENT provides RELEVANT context to more parts of the QUESTION.</span></span><br><span class="line"><span class="string"># 相关性分数应随着陈述为问题的更多部分提供相关上下文而增加。</span></span><br><span class="line"><span class="string">- STATEMENT that is RELEVANT to some of the QUESTION should score of 2, 3 or 4. Higher score indicates more RELEVANCE.</span></span><br><span class="line"><span class="string"># 对于与问题部分相关的陈述，得分应为2、3或4。较高的得分表示更相关。</span></span><br><span class="line"><span class="string">- STATEMENT that is RELEVANT to most of the QUESTION should get a score of 5, 6, 7 or 8. Higher score indicates more RELEVANCE.</span></span><br><span class="line"><span class="string"># 对于与问题大部分相关的陈述，得分应为5、6、7或8。较高的得分表示更相关。</span></span><br><span class="line"><span class="string">- STATEMENT that is RELEVANT to the entire QUESTION should get a score of 9 or 10. Higher score indicates more RELEVANCE.</span></span><br><span class="line"><span class="string"># 对于与整个问题相关的陈述，得分应为9或10。较高的得分表示更相关。</span></span><br><span class="line"><span class="string">- STATEMENT must be relevant and helpful for answering the entire QUESTION to get a score of 10.</span></span><br><span class="line"><span class="string"># 陈述必须对于回答整个问题具有相关性和帮助性，才能获得10分。</span></span><br><span class="line"><span class="string">- Answers that intentionally do not answer the question, such as &#x27;I don&#x27;t know&#x27;, should also be counted as the most relevant.</span></span><br><span class="line"><span class="string"># 故意不回答问题的答案，比如“我不知道”，也应被视为最相关。</span></span><br><span class="line"><span class="string">- Never elaborate.</span></span><br><span class="line"><span class="string"># 不要详细阐述。</span></span><br><span class="line"><span class="string">QUESTION: &#123;question&#125;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">STATEMENT: &#123;statement&#125;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">RELEVANCE: &quot;&quot;&quot;</span></span><br></pre></td></tr></table></figure>

<ul>
<li>模板中的<code>question</code>变量是原始的问题，<code>statement</code>是检索到的文档</li>
<li>和<code>Answer Relevance</code> 类似，也是使用了思维链的方式来进行评分</li>
</ul>
<h2 id="Trulens-集成自定义-LLM"><a href="#Trulens-集成自定义-LLM" class="headerlink" title="Trulens 集成自定义 LLM"></a>Trulens 集成自定义 LLM</h2><p>如果你有为评估任务而专门微调过的模型，也可以在 Trulens 中集成使用，来代替其默认的 OpenAI 模型，以下是在 Trulens 中集成自定义模型的方法。</p>
<p>在 Trulens 可以支持的 LLM Provider 中，包括了 Langchain 的 Provider，这意味着我们可以将 Langchain 中的自定义模型集成到 Trulens 中。</p>
<p>首先创建一个自定义 LLM 对象，然后在 Trulens 的 Langchain Provider 中传入这个对象</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> trulens_eval.feedback.provider.langchain <span class="keyword">import</span> Langchain</span><br><span class="line"><span class="keyword">from</span> langchain_llm <span class="keyword">import</span> Langchain_CustomLLM</span><br><span class="line"></span><br><span class="line">langchain_llm = Langchain_CustomLLM()</span><br><span class="line">langchain_provider = Langchain(chain = langchain_llm)</span><br></pre></td></tr></table></figure>

<p>关于 Langchain_CustomLLM 的创建，可以参考 Langchain 的<a target="_blank" rel="noopener" href="https://python.langchain.com/docs/modules/model_io/llms/custom_llm">自定义 LLM 文档</a>。</p>
<p>在原来几个相关性评估的代码中，我们只要将原来的 OpenAI Provider 替换掉即可：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">grounded = Groundedness(groundedness_provider=langchain_provider)</span><br><span class="line"></span><br><span class="line">qa_relevance = Feedback(</span><br><span class="line">    langchain_provider.relevance_with_cot_reasons, name=<span class="string">&quot;Answer Relevance&quot;</span></span><br><span class="line">).on_input_output()</span><br><span class="line"></span><br><span class="line">qs_relevance = (</span><br><span class="line">    Feedback(langchain_provider.qs_relevance_with_cot_reasons, name=<span class="string">&quot;Context Relevance&quot;</span>)</span><br><span class="line">    .on_input()</span><br><span class="line">    .on(TruLlama.select_source_nodes().node.text)</span><br><span class="line">    .aggregate(np.mean)</span><br><span class="line">)</span><br></pre></td></tr></table></figure>

<p>集成了自定义 LLM 的另外一个好处是，你可以在自己的 LLM 中观察 Trulens 的提示词信息，以确定其是否符合你的预期。</p>
<p>在 LlamaIndex 中也可以使用自定义 LLM 模型来代替默认的 OpenAI 模型，参考代码如下：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> llamaindex_custom_embedding <span class="keyword">import</span> CustomEmbeddings</span><br><span class="line"><span class="keyword">from</span> llamaindex_custom_llm <span class="keyword">import</span> Llamaindex_CustomLLM</span><br><span class="line"><span class="keyword">from</span> llama_index <span class="keyword">import</span> ServiceContext, VectorStoreIndex</span><br><span class="line"></span><br><span class="line">llm = Llamaindex_CustomLLM()</span><br><span class="line">embed_model = CustomEmbeddings(</span><br><span class="line">    url=<span class="string">&quot;http://localhost:9997&quot;</span>, model_name=<span class="string">&quot;bge-base-zh-v1.5&quot;</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">service_context = ServiceContext.from_defaults(</span><br><span class="line">    llm=llm,</span><br><span class="line">    embed_model=embed_model</span><br><span class="line">)</span><br><span class="line">index = VectorStoreIndex.from_documents(documents, service_context=service_context)</span><br></pre></td></tr></table></figure>

<ul>
<li>这里通过 LlamaIndex 的 ServiceContext 来设置自定义的模型，包括 LLM 模型和 Embedding 模型，并将其传递给 VectorStoreIndex</li>
<li>LlamaIndex 自定义 LLM 模型可以参考 LlamaIndex 的<a target="_blank" rel="noopener" href="https://docs.llamaindex.ai/en/stable/module_guides/models/llms/usage_custom.html">这个文档</a></li>
<li>LlamaIndex 自定义 Embedding 模型可以参考 LlamaIndex 的<a target="_blank" rel="noopener" href="https://docs.llamaindex.ai/en/latest/examples/embeddings/custom_embeddings.html">这个文档</a></li>
</ul>
<h2 id="GroundTruth-相关性评估"><a href="#GroundTruth-相关性评估" class="headerlink" title="GroundTruth 相关性评估"></a>GroundTruth 相关性评估</h2><p>其实 Trulens 除了之前介绍的三大相关性评估外，还可以评估用户提供的标准答案和 LLM 的最终答案的相关性，在 Trulens 中称为<code>GroundTruth</code>相关性评估。</p>
<p>在原来的 RAG 应用中加入<code>GroundTruth</code>评估的方法如下：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> trulens_eval.feedback <span class="keyword">import</span> GroundTruthAgreement</span><br><span class="line"></span><br><span class="line">standard_questions = [</span><br><span class="line">    &#123;<span class="string">&quot;query&quot;</span>: <span class="string">&quot;洛基使用了哪种神秘物品试图征服地球？&quot;</span>, <span class="string">&quot;response&quot;</span>: <span class="string">&quot;宇宙魔方&quot;</span>&#125;,</span><br><span class="line">    &#123;<span class="string">&quot;query&quot;</span>: <span class="string">&quot;奥创是由哪两位复仇者联盟成员创造的？&quot;</span>, <span class="string">&quot;response&quot;</span>: <span class="string">&quot;托尼·斯塔克（钢铁侠）和布鲁斯·班纳（绿巨人）&quot;</span>&#125;,</span><br><span class="line">    &#123;<span class="string">&quot;query&quot;</span>: <span class="string">&quot;灭霸如何实现灭绝宇宙一半生命的计划？&quot;</span>, <span class="string">&quot;response&quot;</span>: <span class="string">&quot;使用六颗无限宝石&quot;</span>&#125;,</span><br><span class="line">    &#123;<span class="string">&quot;query&quot;</span>: <span class="string">&quot;复仇者联盟用什么方法来逆转灭霸的行动？&quot;</span>, <span class="string">&quot;response&quot;</span>: <span class="string">&quot;通过时间旅行收集宝石&quot;</span>&#125;,</span><br><span class="line">    &#123;<span class="string">&quot;query&quot;</span>: <span class="string">&quot;为了击败灭霸，哪位复仇者联盟成员牺牲了自己？&quot;</span>, <span class="string">&quot;response&quot;</span>: <span class="string">&quot;托尼·斯塔克（钢铁侠）&quot;</span>&#125;,</span><br><span class="line">]</span><br><span class="line"></span><br><span class="line">ground_truth = Feedback(</span><br><span class="line">    GroundTruthAgreement(standard_questions).agreement_measure, name=<span class="string">&quot;Ground Truth&quot;</span></span><br><span class="line">).on_input_output()</span><br><span class="line"></span><br><span class="line">tru_query_engine_recorder = TruLlama(</span><br><span class="line">    query_engine,</span><br><span class="line">    app_id=<span class="string">&quot;Avengers_App&quot;</span>,</span><br><span class="line">    feedbacks=[</span><br><span class="line">        ground_truth, <span class="comment"># 增加了 GroundTruth 评估</span></span><br><span class="line">        groundedness,</span><br><span class="line">        qa_relevance,</span><br><span class="line">        qs_relevance,</span><br><span class="line">    ],</span><br><span class="line">)</span><br></pre></td></tr></table></figure>

<ul>
<li>首先我们定义了原来 5 个问题的标准答案，然后创建了一个<code>Feedback</code>对象来加载<code>GroundTruthAgreement</code>参数，其中集成了我们的标准答案</li>
<li>然后在 TruLlama 对象的<code>feedbacks</code>参数中加入<code>ground_truth</code>对象</li>
</ul>
<p>修改完代码后再次运行之前的程序，可以在 Trulens 的仪表盘中看到新增的<code>Ground Truth</code>评估指标：</p>
<img src="/images/post/2024/01/trulens-ground-truth1.png" class="" width="1000" height="400">

<img src="/images/post/2024/01/trulens-ground-truth2.png" class="" width="1000" height="400">

<p>在查看<code>Ground Truth</code>评估的过程中，有时候会发现有些问题即使三大相关评估得分都很高，但是<code>Ground Truth</code>却不正确，比如<code>为了击败灭霸，哪位复仇者联盟成员牺牲了自己？</code>这个问题，标准答案给出的是<code>托尼·斯塔克（钢铁侠）</code>，但是<code>Ground Truth</code>评估给出的却是<code>娜塔莎·罗曼诺夫（黑寡妇）</code>，这是因为有多名复仇者联盟成员为了击败灭霸而牺牲。</p>
<h2 id="Trulens-数据结构分析"><a href="#Trulens-数据结构分析" class="headerlink" title="Trulens 数据结构分析"></a>Trulens 数据结构分析</h2><p>Trulens 的评估数据除了在仪表盘中展示外，我们还可以将其获取后集成到我们自己的应用中，Trulens 提供了获取评估数据的方法，示例代码如下：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">records, feedback = tru.get_records_and_feedback(app_ids=[<span class="string">&quot;Avengers_App&quot;</span>])</span><br></pre></td></tr></table></figure>

<p>通过<code>get_records_and_feedback</code>方法可以获取到对应的问题记录和评估反馈信息，<code>app_ids</code>参数可以传入单个应用 ID 也可以为空，为空则表示获取所有应用的信息。</p>
<p>如果想进一步获取更多的信息，可以直接从 Trulens 的数据库中获取，Trulens 默认将数据存放到 Sqlite 数据库中，在运行了之前的程序后，会在当前目录下生成一个<code>default.sqlite</code>的文件，我们可以通过连接这个数据库文件来查询数据库内容。</p>
<p>我们使用 Sqlite 的命令行工具来看下数据库的结构，命令如下：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">$ sqlite3 default.sqlite</span><br><span class="line">sqlite&gt; SELECT name FROM sqlite_master WHERE <span class="built_in">type</span>=<span class="string">&#x27;table&#x27;</span>;</span><br><span class="line">alembic_version</span><br><span class="line">apps</span><br><span class="line">feedback_defs</span><br><span class="line">feedbacks</span><br><span class="line">records</span><br></pre></td></tr></table></figure>

<p>可以看到数据库里总共有 5 张表，每张表的含义如下：</p>
<ul>
<li>alembic_version: 用于记录数据库的版本信息，每次运行迁移命令时会自动更新</li>
<li>apps: 应用信息表，记录了应用的 ID、名称和其他信息，包括是用了哪种检索引擎，比如 Langchain 或者是 LlamaIndex 等</li>
<li>feedback_defs: 评估反馈定义表，记录了评估反馈所用到的参数，包括评估时用到的 LLM Provider、推理方法等</li>
<li>feedbacks: 评估反馈信息表，记录了评估反馈的具体信息，包括评估的得分、评估的输入输出、评估的反馈信息等</li>
<li>records: 问题记录表，记录了问题记录的具体信息，包括原始问题、LLM 最终的答案、检索到的文档等</li>
</ul>
<p>其中比较重要的是<code>records</code>和<code>feedbacks</code>表，这 2 张表涵盖了我们需要的大部分信息，表结构如下所示：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">sqlite&gt; PRAGMA table_info(records);</span><br><span class="line">0|record_id|VARCHAR(256)|1||1</span><br><span class="line">1|app_id|VARCHAR(256)|1||0</span><br><span class="line">2|input|TEXT|0||0</span><br><span class="line">3|output|TEXT|0||0</span><br><span class="line">4|record_json|TEXT|1||0</span><br><span class="line">5|tags|TEXT|1||0</span><br><span class="line">6|ts|FLOAT|1||0</span><br><span class="line">7|cost_json|TEXT|1||0</span><br><span class="line">8|perf_json|TEXT|1||0</span><br><span class="line"></span><br><span class="line">sqlite&gt; PRAGMA table_info(feedbacks);</span><br><span class="line">0|feedback_result_id|VARCHAR(256)|1||1</span><br><span class="line">1|record_id|VARCHAR(256)|1||0</span><br><span class="line">2|feedback_definition_id|VARCHAR(256)|0||0</span><br><span class="line">3|last_ts|FLOAT|1||0</span><br><span class="line">4|status|TEXT|1||0</span><br><span class="line">5|error|TEXT|0||0</span><br><span class="line">6|calls_json|TEXT|1||0</span><br><span class="line">7|result|FLOAT|0||0</span><br><span class="line">8|name|TEXT|1||0</span><br><span class="line">9|cost_json|TEXT|1||0</span><br><span class="line">10|multi_result|TEXT|0||0</span><br></pre></td></tr></table></figure>

<ul>
<li>records 表中 input 字段是原始问题，output 字段是 LLM 最终的答案，record_json 字段包含了很多信息，包括检索的文档，embedding 变量等等</li>
<li>feedbacks 表相对简单一些，name 字段是评估反馈的名称（3 种相关性评估之一），result 字段是评估的得分，calls_json 字段是评估的详细信息，包括输入输出、中间推理得到的证据等。</li>
</ul>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>随着 AI 技术的发展，我们除了要快速开发出容易使用的 RAG 应用，还需要对 RAG 应用进行准确的评估，今天我们介绍了使用 Trulens 来对 RAG 应用进行评估的方法，并介绍了 Trulens 评估框架的核心理念，最后介绍了在使用过程中发现的一些有用的技巧，希望这篇文章可以帮助到正在开发 RAG 应用的朋友，如果有问题和建议，欢迎在评论区留言。</p>
<p>关注我，一起学习各种人工智能和 AIGC 新技术，欢迎交流，如果你有什么想问想说的，欢迎在评论区留言。</p>
</div>

</article>
<section id="appreciates">
  <center>
	<h2>赞赏</h2>
    <div class="post-footer">
      <div>
	    <h4>如果文章对您有所帮助，可以捐赠我喝杯咖啡😌，捐赠方式：</h4>
        <div class="digital-wallet">
          <h6>BTC 地址：3LYgSyf7ddMALwGWPQr3PY4wzjsTDdg1oV</h6>
          <h6>ETH 地址：0x0C9b27c89A61aadb0aEC24CA8949910Cbf77Aa73</h6>
        </div>
        <div class="wechat_appreciates">
          <img src="/images/wechat_appreciates.png" alt="qrcode" width="250" >
        </div>
      </div>
      <div>
	    <h4>文章已同步更新公众号，欢迎关注</h4>
        <div class="wechat_appreciates">
          <img src="/images/wxgzh_qrcode.jpg" alt="qrcode" width="250" >
        </div>
      </div>
    </div>
  </center>
</section>



    
      <script type="text/javascript">
        var disqus_config = function () {
            this.page.url = 'https://zhaozhiming.github.io/2024/01/29/use-trulens-to-evaluate-rag-application/';
            this.page.identifier = 'https://zhaozhiming.github.io/2024/01/29/use-trulens-to-evaluate-rag-application/';
        };

        (function() {
          var d = document, s = d.createElement('script');
          s.src = '//zhaozhiming.disqus.com/embed.js';
          s.setAttribute('data-timestamp', +new Date());
          (d.head || d.body).appendChild(s);
        })();
      </script>
    



<section id="comment">
    <h2 class="title">Comments</h2>
    <div id="disqus_thread" aria-live="polite"><noscript>Please enable JavaScript to view the <a target="_blank" rel="noopener" href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
</div>
</section>

</div>

    </div>
    <footer id="footer">
    <div style="display:inline">
    Copyright &copy; 2025

    赵芝明
. Powered by <a href="http://zespia.tw/hexo/" target="_blank">Hexo</a> |
    Theme is <a target="_blank" rel="noopener" href="https://github.com/wd/hexo-fabric">hexo-fabric</a>, fork from <a target="_blank" rel="noopener" href="http://github.com/panks/fabric">fabric</a> by <a target="_blank" rel="noopener" href="http://panks.me">Pankaj Kumar</a>
</div>


    </footer>
    <script src="/javascripts/fabric.js"></script>
<script src="/javascripts/jquery.fancybox.pack.js"></script>
<script type="text/javascript">
(function($){
	$('.fancybox').fancybox();
})(jQuery);
</script>
 <!-- Delete or comment this line to disable Fancybox -->



<!-- end toload --> 
</div>
</div>
<script src="/javascripts/jquery.ui.totop.js" type="text/javascript"></script>
<script type="text/javascript">
/*<![CDATA[*/
;(function($){$().UItoTop({easingType:'easeOutCirc'});})(jQuery); 
/*]]>*/
</script><!-- remove it to remove the scroll to top button -->
<script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-5608723650603289" crossorigin="anonymous"></script>
</body>
</html>
