<!DOCTYPE HTML>
<html>
<head>
	<meta charset="utf-8">
    
	<title>高级 RAG 检索策略之句子窗口检索 - Hacker and Geeker&#39;s Way</title>
    <meta name="author" content="">
    
	<meta name="description" content="使用句子窗口进行高级 RAG 检索"> <!-- TODO: truncate -->
	<meta name="keywords" content="rag, llamaindex, sentence window">
	<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">

	<link href="atom.xml" rel="alternate" title="Hacker and Geeker&#39;s Way" type="application/atom+xml">
	<link href="/favicon.ico" rel="shortcut icon">
    <link href="/stylesheets/screen.css" media="screen, projection" rel="stylesheet" type="text/css">
    <link href="/stylesheets/custom.css" media="screen, projection" rel="stylesheet" type="text/css">
    <link href="/stylesheets/hljs.css" media="screen, projection" rel="stylesheet" type="text/css">

    <link href='/stylesheets/font.css?family=Slackey' rel='stylesheet' type='text/css'>
    <link href='/stylesheets/font.css?family=Fjalla+One' rel='stylesheet' type='text/css'>
    <link href='/stylesheets/font.css?family=Amethysta+One' rel='stylesheet' type='text/css'>
	  <script src="/javascripts/jquery.min.js"></script>
    <!--[if lt IE 9]><script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script><![}]-->

    <script type="text/javascript" src="/javascripts/jquery-tapir.js"></script>

    <!-- remove or comment it to disable ajaxification -->   
    <!-- <script src="/javascripts/ajaxify.js"></script> -->

    

    
	<script type="text/javascript">
		var _gaq = _gaq || [];
		_gaq.push(['_setAccount', 'UA-100485541-1']);
		_gaq.push(['_trackPageview']);

		(function() {
			var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
			ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
			var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
		})();
	</script>


<meta name="generator" content="Hexo 6.3.0"></head>


<body>
    <div id="wrapper">
    <header id="header" class="inner"><!-- for more effects see _animate.scss -->
<h1 class="animated bounceInDown">
    <div id="headerbg">
        Hacker and Geeker&#39;s Way
    </div>
</h1>
<span class="subtitle"></span>
<br>

<ul id="social-links" style="text-align:center; clear:both;">
  
  <!-- GitHub -->
  <li>
  <a target="_blank" rel="noopener" href="https://github.com/zhaozhiming" class="github" title="Github"></a>
  </li>
  
  
  
  
  <!-- Twitter -->
  <li>
  <a target="_blank" rel="noopener" href="http://www.twitter.com/kingzzm" class="twitter" title="Twitter"></a>
  </li>
  
  
  <!-- LinkedIn -->
  <li>
  <a target="_blank" rel="noopener" href="http://www.linkedin.com/in/zhaozhiming" class="linkedin" title="LinkedIn"></a>
  </li>
  
  
  
  
  
  <!-- Stackoverflow -->
  <li>
  <a target="_blank" rel="noopener" href="http://stackoverflow.com/users/1954315/zhaozhiming" class="stackoverflow" title="Stackoverflow"></a>
  </li>
  
</ul>


<!-- use full url including 'index.html' for navigation bar if you are using ajax -->
<ul id="nav">
	<li id="ajax"><a href="/index.html">Home</a></li>
	<li id="ajax"><a href="/archives/index.html">Archives</a></li>
    <li><a href="/atom.xml">RSS</a></li>
    <li><a href="/about/index.html">About</a></li>
    
    <li>
    <div id="dark">
        <form action="//www.google.com.hk/search" method="get" accept-charset="UTF-8" id="search">
            <input type="hidden" name="sitesearch" value="https://zhaozhiming.github.io" />
            <input type="text" name="q" results="0" placeholder="Search..." x-webkit-speech />
        </form>
    </div>
    </li>
        
</ul>




</header>


<div id="toload">
<!-- begin toload -->
    <div id="content">
        <div class="inner">
<article class="post">
	<h2 class="title">高级 RAG 检索策略之句子窗口检索</h2>
    <div class="meta">
        <div class="date">Published on: <time datetime="2024-03-11T01:45:46.000Z" itemprop="datePublished">3月 11, 2024</time>
</div>
        <div class="tags">Tags: 

<a href="/tags/llamaindex/">llamaindex</a> <a href="/tags/rag/">rag</a> <a href="/tags/sentence-window/">sentence window</a>
</div>
    </div>
	<div class="entry-content"><img src="/images/post/2024/03/sentence-window.jpg" class="" width="400" height="300">

<p>之前介绍过大语言模型（LLM）相关技术 RAG（Retrieval Augmented Generation）的内容，但随着 LLM 技术的发展，越来越多的高级 RAG 检索方法也随之被人发现，相对于普通的 RAG 检索，高级 RAG 通过更深化的技术细节、更复杂的搜索策略，提供出了更准确、更相关、更丰富的信息检索结果。今天我们就来介绍一下高级 RAG 检索策略其中的一种方法——句子窗口检索。</p>
<span id="more"></span>

<h2 id="句子窗口检索介绍"><a href="#句子窗口检索介绍" class="headerlink" title="句子窗口检索介绍"></a>句子窗口检索介绍</h2><p>在介绍句子窗口检索之前，我们先简单介绍一下普通的 RAG 检索，下面是普通 RAG 检索的流程图：</p>
<img src="/images/post/2024/03/base-rag.png" class="" width="1000" height="600">

<ul>
<li>先将文档切片成大小相同的块</li>
<li>将切片后的块进行 Embedding 并保存到向量数据库</li>
<li>根据问题检索出 Embedding 最相似的 K 个文档库</li>
<li>将问题和检索结果一起交给 LLM 生成答案</li>
</ul>
<p>普通 RAG 检索的问题是如果文档切片比较大的话，检索结果可能会包含很多无关信息，从而导致 LLM 生成的结果不准确。我们再来看下句子窗口检索的流程图：</p>
<img src="/images/post/2024/03/sentence-window-rag.png" class="" width="1000" height="600">

<ul>
<li>和普通 RAG 检索相比，句子窗口检索的文档切片单位更小，通常以句子为单位</li>
<li>在检索时，除了检索到匹配度最高的句子，还将该句子周围的上下文也作为检索结果一起提交给 LLM</li>
</ul>
<p>句子窗口检索让检索内容更加准确，同时上下文窗口又能保证检索结果的丰富性。</p>
<h3 id="原理"><a href="#原理" class="headerlink" title="原理"></a>原理</h3><p>句子窗口检索的原理其实很简单，首先在文档切分时，将文档以句子为单位进行切分，同时进行 Embedding 并保存数据库。然后在检索时，通过问题检索到相关的句子，但并不只是将检索到的句子作为检索结果，而是将该句子前面和后面的句子一起作为检索结果，包含的句子数量可以通过参数来进行设置，最后将检索结果再一起提交给 LLM 来生成答案。</p>
<img src="/images/post/2024/03/sentence-window-rag-principle.jpg" class="" width="1000" height="600">

<p>我们再通过示例代码来理解句子窗口检索的原理，在 RAG 框架中，<a target="_blank" rel="noopener" href="https://www.llamaindex.ai/">LlamaIndex</a>很好地实现了句子窗口检索的功能，下面我们就用 LlamxIndex 来演示句子窗口检索的功能。</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> llama_index.core.node_parser <span class="keyword">import</span> SentenceWindowNodeParser</span><br><span class="line"><span class="keyword">from</span> llama_index.core.schema <span class="keyword">import</span> Document</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">node_parser = SentenceWindowNodeParser.from_defaults(</span><br><span class="line">    window_size=<span class="number">3</span>,</span><br><span class="line">    window_metadata_key=<span class="string">&quot;window&quot;</span>,</span><br><span class="line">    original_text_metadata_key=<span class="string">&quot;original_text&quot;</span>,</span><br><span class="line">)</span><br><span class="line">text = <span class="string">&quot;hello. how are you? I am fine! Thank you. And you? I am fine too. &quot;</span></span><br><span class="line"></span><br><span class="line">nodes = node_parser.get_nodes_from_documents([Document(text=text)])</span><br></pre></td></tr></table></figure>

<ul>
<li>使用 SentenceWindowNodeParser 创建一个文档解析器，设置<code>window_size</code>为 3，这意味着句子窗口最多会包含 7 个句子，包括检索到的句子前面 3 个句子、检索到的句子本身以及检索到的句子后面 3 个句子</li>
<li>使用文档解析器对文档进行解析，解析后的结果会包含<code>window</code>和<code>original_text</code>两个元数据</li>
<li><code>window_metadata_key</code>是指保存句子窗口包含的所有句子的键值，而<code>original_text_metadata_key</code>是指检索到的句子的键值</li>
<li>最后通过文档解析器将原始文档进行解析</li>
</ul>
<p><strong>注意</strong>：在之前的版本，句子窗口只会添加检索到的句子后面 2 个句子，也就是说在默认<code>window-size=3</code>的情况下，句子窗口总共只会包含 6 个句子，但新版本将核心功能提取成<code>llama-index-core</code>后，句子窗口会将检索到的句子后面的 3 个句子作为窗口，更多的信息可以查看<a target="_blank" rel="noopener" href="https://github.com/run-llama/llama_index/blob/main/llama-index-core/llama_index/core/node_parser/text/sentence_window.py#L101">官方仓库代码</a>。</p>
<p>我们再来看解析后的 nodes 中的内容，首先我们看第一个 node:</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(nodes[<span class="number">0</span>].metadata)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 显示结果</span></span><br><span class="line">&#123;<span class="string">&#x27;window&#x27;</span>: <span class="string">&#x27;hello.  how are you?  I am fine!  Thank you. &#x27;</span>, <span class="string">&#x27;original_text&#x27;</span>: <span class="string">&#x27;hello. &#x27;</span>&#125;</span><br></pre></td></tr></table></figure>

<p>可以看到当检索到的句子是第 1 个句子时，因为该句子前面没有其他句子，所以句子窗口总共包含了 4 个句子，也就是检索到的句子本身再加上后面的 3 个句子。</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(nodes[<span class="number">3</span>].metadata)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 显示结果</span></span><br><span class="line">&#123;<span class="string">&#x27;window&#x27;</span>: <span class="string">&#x27;hello.  how are you?  I am fine!  Thank you.  And you?  I am fine too. &#x27;</span>, <span class="string">&#x27;original_text&#x27;</span>: <span class="string">&#x27;Thank you. &#x27;</span>&#125;</span><br></pre></td></tr></table></figure>

<p>当检索到的句子是第 4 个句子时，句子窗口就会包含检索到的句子前 3 个句子、检索到的句子本身以及检索到的句子后面 3 个句子，但因为后面只有 2 个句子，所以总共就只有 6 个句子。</p>
<h3 id="中文句子切分"><a href="#中文句子切分" class="headerlink" title="中文句子切分"></a>中文句子切分</h3><p>句子窗口解析器一般以英文中句子结束的标点符号来切分句子，默认的标点符号有<code>.?!</code>等，但如果是中文的话，这种切分方式就会失效，但我们可以在文档解析器中增加解析规则参数来解决这个问题：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> re</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">sentence_splitter</span>(<span class="params">text</span>):</span><br><span class="line">    nodes = re.split(<span class="string">&quot;(?&lt;=。)|(?&lt;=？)|(?&lt;=！)&quot;</span>, text)</span><br><span class="line">    nodes = [node <span class="keyword">for</span> node <span class="keyword">in</span> nodes <span class="keyword">if</span> node]</span><br><span class="line">    <span class="keyword">return</span> nodes</span><br><span class="line"></span><br><span class="line">node_parser = SentenceWindowNodeParser.from_defaults(</span><br><span class="line">    window_size=<span class="number">3</span>,</span><br><span class="line">    window_metadata_key=<span class="string">&quot;window&quot;</span>,</span><br><span class="line">    original_text_metadata_key=<span class="string">&quot;original_text&quot;</span>,</span><br><span class="line">    sentence_splitter=sentence_splitter,</span><br><span class="line">)</span><br></pre></td></tr></table></figure>

<p>我们增加了<code>sentence_splitter</code>参数，并传入自定义的<code>sentence_splitter</code>函数，这个函数的作用就是将文档按照中文标点符号进行切分。</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">text = <span class="string">&quot;你好。你好吗？我很好！谢谢。你呢？我也很好。 &quot;</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(nodes[<span class="number">0</span>].metadata)</span><br><span class="line"><span class="built_in">print</span>(nodes[<span class="number">3</span>].metadata)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 显示结果</span></span><br><span class="line">&#123;<span class="string">&#x27;window&#x27;</span>: <span class="string">&#x27;你好。 你好吗？ 我很好！ 谢谢。&#x27;</span>, <span class="string">&#x27;original_text&#x27;</span>: <span class="string">&#x27;你好。&#x27;</span>&#125;</span><br><span class="line">&#123;<span class="string">&#x27;window&#x27;</span>: <span class="string">&#x27;你好。 你好吗？ 我很好！ 谢谢。 你呢？ 我也很好。  &#x27;</span>, <span class="string">&#x27;original_text&#x27;</span>: <span class="string">&#x27;谢谢。&#x27;</span>&#125;</span><br></pre></td></tr></table></figure>

<p>可以看到，替换了解析规则后，解析器解析出来的句子和英文解析时的效果是一样的。</p>
<h2 id="句子窗口使用"><a href="#句子窗口使用" class="headerlink" title="句子窗口使用"></a>句子窗口使用</h2><p>下面我们再来看看句子窗口检索在实际 RAG 项目中的使用，文档数据我们还是使用之前维基百科上的<a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Avenger">复仇者联盟</a>电影剧情来进行测试。</p>
<h3 id="普通-RAG-检索示例"><a href="#普通-RAG-检索示例" class="headerlink" title="普通 RAG 检索示例"></a>普通 RAG 检索示例</h3><p>首先我们看下普通 RAG 检索在文档切分和检索时的效果：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> llama_index.core <span class="keyword">import</span> SimpleDirectoryReader</span><br><span class="line"><span class="keyword">from</span> llama_index.core.node_parser <span class="keyword">import</span> SentenceSplitter</span><br><span class="line"><span class="keyword">from</span> llama_index.core.settings <span class="keyword">import</span> Settings</span><br><span class="line"><span class="keyword">from</span> llama_index.core <span class="keyword">import</span> VectorStoreIndex</span><br><span class="line"><span class="keyword">from</span> llama_index.embeddings.openai <span class="keyword">import</span> OpenAIEmbedding</span><br><span class="line"></span><br><span class="line">documents = SimpleDirectoryReader(<span class="string">&quot;./data&quot;</span>).load_data()</span><br><span class="line">text_splitter = SentenceSplitter()</span><br><span class="line"></span><br><span class="line">llm = OpenAI(model=<span class="string">&quot;gpt-3.5-turbo&quot;</span>, temperature=<span class="number">0.1</span>)</span><br><span class="line">embed_model = OpenAIEmbedding()</span><br><span class="line">Settings.llm = llm</span><br><span class="line">Settings.embed_model = embed_model</span><br><span class="line">Settings.node_parser = text_splitter</span><br><span class="line"></span><br><span class="line">base_index = VectorStoreIndex.from_documents(</span><br><span class="line">    documents=documents,</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">base_engine = base_index.as_query_engine(</span><br><span class="line">    similarity_top_k=<span class="number">2</span>,</span><br><span class="line">)</span><br></pre></td></tr></table></figure>

<ul>
<li>我们使用 LlamaIndex 创建了一个普通 RAG 检索，首先从<code>data</code>目录中加载文档</li>
<li>使用<code>SentenceSplitter</code>作为文档解析器对文档进行解析，与默认的<code>TokenTextSplitter</code>不同，<code>SentenceSplitter</code>切分后的块一般会包含完整的句子，而不会出现部分句子的情况</li>
<li>使用 OpenAI 的 Embedding 和 LLM 模型进行文档 Embedding 和生成答案，LlamaIndex 最新版本使用了<code>Setting</code>参数来代替原来的<code>ServiceContext</code></li>
<li>最后创建一个查询引擎，只获取相关度最高的 2 个文档作为检索结果</li>
</ul>
<p>再来看测试的结果：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">question = <span class="string">&quot;奥创是由哪两位复仇者联盟成员创造的？&quot;</span></span><br><span class="line">response = base_engine.query(question)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;response: <span class="subst">&#123;response&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;len: <span class="subst">&#123;<span class="built_in">len</span>(response.source_nodes)&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line">text = response.source_nodes[<span class="number">0</span>].node.text</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;------------------&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Text: <span class="subst">&#123;text&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line">text = response.source_nodes[<span class="number">1</span>].node.text</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;------------------&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Text: <span class="subst">&#123;text&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 显示结果</span></span><br><span class="line">response: 奥创是由托尼·斯塔克和布鲁斯·班纳这两位复仇者联盟成员创造的。</span><br><span class="line"><span class="built_in">len</span>: <span class="number">2</span></span><br><span class="line">------------------</span><br><span class="line">Text: 神盾局解散后，由托尼·斯塔克、史蒂芬·罗杰斯、雷神、娜塔莎·罗曼诺夫、布鲁斯·班纳以及克林特·巴顿组成的复仇者联盟负责全力搜查九头蛇的下落，这次透过“盟友”提供的情报而进攻位于东欧的国家“索科维亚”的科研基地，基地负责人沃夫冈·冯·斯特拉克释放出以洛基的令牌力量获得异能力的皮特洛和旺达·马克希莫夫兄妹。皮特洛用超音速击败巴顿，旺达暗中用幻象术迷惑托尼的大脑，利用他内心的“恐惧创伤”动摇他。两兄妹逃跑后，复仇者成功攻下基地，斯特拉克被军方捕获，令牌也被复仇者回收。全体复仇者回到纽约的复仇者大楼，托尼分析令牌内部发现里面的一种罕见的人工智能生命体，被创伤所动摇的他而决定将其用于军事方面。透过和班纳夜以继日的研究，两人创造出名叫“奥创”的强大人工智能。</span><br><span class="line"></span><br><span class="line">奥创刚苏醒不久便从网络调阅关于复仇者的各种资料，将危害世界的源头怪罪于人类，他摧毁托尼的人工智能贾维斯，操纵一架破损机器人来到复仇者的庆祝派对，讽刺他们以杀人凶手的身份来塑造英雄本色，操控其余机器人发起攻击时抢走令牌。奥创用网络将自己的意识回到索科维亚的九头蛇基地，重启斯特拉克留下的机器人实验拼凑一个全新机体和他的大量机器人，并召来皮特洛与旺达作为同伴。玛丽亚·希尔汇报奥创杀死狱中的斯特拉克，但也找到一位和斯特拉克合作的南非军火商尤里西斯·克劳，得知他掌有存储于非洲隐密国家瓦坎达的稀有金属振金。</span><br><span class="line"></span><br><span class="line">奥创来到克劳位于南非的武器船厂获取所有振金，并砍断克劳的左手。复仇者们到达后跟他们正面交锋，但大多数人被旺达用幻象术迷惑，看到各自心中最深层的“阴影”；唯独托尔看见在家乡阿萨神域发生的不明景象。</span><br><span class="line">------------------</span><br><span class="line">Text: 奥创来到克劳位于南非的武器船厂获取所有振金，并砍断克劳的左手。复仇者们到达后跟他们正面交锋，但大多数人被旺达用幻象术迷惑，看到各自心中最深层的“阴影”；唯独托尔看见在家乡阿萨神域发生的不明景象。旺达同时迷惑班纳的大脑，使其丧失理智而变成绿巨人跑到约翰内斯堡大肆破坏。托尼摧毁奥创却发现其主意识早已逃跑，之后换上阻止绿巨人失控情形准备的绿巨人毁灭者而幸运将班纳制伏。吃败仗的复仇者集体撤离至巴顿位于郊区的安全屋，结识巴顿的妻子与孩子们，尼克·弗瑞再次现身激励复仇者。托尔在意他看见的幻象而暂时离队，去找老友埃里克·塞尔维格格探讨自己所看到的幻象。奥创在韩国首尔找到与复仇者合作的韩裔遗传学家海伦·赵，命令她立即着手“再生摇篮”：利用人造组织、振金与令牌中镶的宝石，为他造一个完美无缺、更接近人类的身体。</span><br><span class="line"></span><br><span class="line">意识传输期间，旺达透视奥创的思想看见他企图灭绝所有人类的真正目的，兄妹俩顿时发现他们在玩火自焚，旺达便解除海伦的心灵控制后使得连线断开，与皮特洛背叛奥创后在第一时间逃跑。史蒂芬追上货车与奥创对打，而皮特洛与旺达决定加入复仇者与奥创对抗。在货车争夺战中，众人成功夺回摇篮，但娜塔莎也被奥创抓走。托尼寻到躲入网络得以幸存的贾维斯后，跟班纳合作将其输进摇篮中，对此反对的史蒂芬、皮特洛与旺达因此跟他们发生冲突。托尔突然回归并用雷电启动摇篮，解释自己这次出行了解到令牌中是六种无限宝石之一的心灵宝石。此刻，摇篮中的身体“幻视”成功跟贾维斯与心灵宝石合成苏醒，表示自己虽然与奥创同是人工智能机器人，但是会站在“生命”的一方。所有人跟随娜塔莎发出的求救信号回到索科维亚，首先争取时间开始疏散城市市民。</span><br></pre></td></tr></table></figure>

<ul>
<li>普通 RAG 检索的答案是正确的，因为检索到文档中包含了与答案相关的内容</li>
<li>普通 RAG 检索的相关文档有 2 个，按照相似度进行了排序</li>
</ul>
<h3 id="句子窗口检索示例"><a href="#句子窗口检索示例" class="headerlink" title="句子窗口检索示例"></a>句子窗口检索示例</h3><p>我们再来看看句子窗口检索在项目中的效果：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> llama_index.core.node_parser <span class="keyword">import</span> SentenceWindowNodeParser</span><br><span class="line"><span class="keyword">from</span> llama_index.core.indices.postprocessor <span class="keyword">import</span> MetadataReplacementPostProcessor</span><br><span class="line"></span><br><span class="line">node_parser = SentenceWindowNodeParser.from_defaults(</span><br><span class="line">    window_size=<span class="number">3</span>,</span><br><span class="line">    window_metadata_key=<span class="string">&quot;window&quot;</span>,</span><br><span class="line">    original_text_metadata_key=<span class="string">&quot;original_text&quot;</span>,</span><br><span class="line">)</span><br><span class="line">documents = SimpleDirectoryReader(<span class="string">&quot;./data&quot;</span>).load_data()</span><br><span class="line"></span><br><span class="line">llm = OpenAI(model=<span class="string">&quot;gpt-3.5-turbo&quot;</span>, temperature=<span class="number">0.1</span>)</span><br><span class="line">embed_model = OpenAIEmbedding()</span><br><span class="line">Settings.llm = llm</span><br><span class="line">Settings.embed_model = embed_model</span><br><span class="line">Settings.node_parser = node_parser</span><br><span class="line"></span><br><span class="line">sentence_index = VectorStoreIndex.from_documents(</span><br><span class="line">    documents=documents,</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">postproc = MetadataReplacementPostProcessor(target_metadata_key=<span class="string">&quot;window&quot;</span>)</span><br><span class="line">sentence_window_engine = sentence_index.as_query_engine(</span><br><span class="line">    similarity_top_k=<span class="number">2</span>, node_postprocessors=[postproc]</span><br><span class="line">)</span><br></pre></td></tr></table></figure>

<ul>
<li>句子窗口检索的代码与普通 RAG 检索有一些差别，第一个不同点是使用了<code>SentenceWindowNodeParser</code>来作为文档解析器，这个我们之前已经介绍过了</li>
<li>第二个不同点是使用了<code>MetadataReplacementPostProcessor</code>来对检索结果进行后处理，将检索结果替换成<code>window</code>这个元数据的值</li>
</ul>
<p>测试结果如下：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line">response = sentence_window_engine.query(question)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;response: <span class="subst">&#123;response&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;len: <span class="subst">&#123;<span class="built_in">len</span>(response.source_nodes)&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line">window = response.source_nodes[<span class="number">0</span>].node.metadata[<span class="string">&quot;window&quot;</span>]</span><br><span class="line">sentence = response.source_nodes[<span class="number">0</span>].node.metadata[<span class="string">&quot;original_text&quot;</span>]</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;------------------&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Window: <span class="subst">&#123;window&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;------------------&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Original Sentence: <span class="subst">&#123;sentence&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line">window = response.source_nodes[<span class="number">1</span>].node.metadata[<span class="string">&quot;window&quot;</span>]</span><br><span class="line">sentence = response.source_nodes[<span class="number">1</span>].node.metadata[<span class="string">&quot;original_text&quot;</span>]</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;------------------&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Window : <span class="subst">&#123;window&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;------------------&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Original Sentence: <span class="subst">&#123;sentence&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 显示结果</span></span><br><span class="line">response: 奥创是由托尼·斯塔克和布鲁斯·班纳创造的。</span><br><span class="line"><span class="built_in">len</span>: <span class="number">2</span></span><br><span class="line">------------------</span><br><span class="line">Window: 神盾局解散后，由托尼·斯塔克、史蒂芬·罗杰斯、雷神、娜塔莎·罗曼诺夫、布鲁斯·班纳以及克林特·巴顿组成的复仇者联盟负责全力搜查九头蛇的下落，这次透过“盟友”提供的情报而进攻位于东欧的国家“索科维亚”的科研基地，基地负责人沃夫冈·冯·斯特拉克释放出以洛基的令牌力量获得异能力的皮特洛和旺达·马克希莫夫兄妹。 皮特洛用超音速击败巴顿，旺达暗中用幻象术迷惑托尼的大脑，利用他内心的“恐惧创伤”动摇他。 两兄妹逃跑后，复仇者成功攻下基地，斯特拉克被军方捕获，令牌也被复仇者回收。 全体复仇者回到纽约的复仇者大楼，托尼分析令牌内部发现里面的一种罕见的人工智能生命体，被创伤所动摇的他而决定将其用于军事方面。</span><br><span class="line">------------------</span><br><span class="line">Original Sentence: 神盾局解散后，由托尼·斯塔克、史蒂芬·罗杰斯、雷神、娜塔莎·罗曼诺夫、布鲁斯·班纳以及克林特·巴顿组成的复仇者联盟负责全力搜查九头蛇的下落，这次透过“盟友”提供的情报而进攻位于东欧的国家“索科维亚”的科研基地，基地负责人沃夫冈·冯·斯特拉克释放出以洛基的令牌力量获得异能力的皮特洛和旺达·马克希莫夫兄妹。</span><br><span class="line">------------------</span><br><span class="line">Window : 合成器启动使整块陆地全速下坠，托尼与托尔联手使合成器超载、赶在撞击地面前在空中瓦解。 奥创转移意识至一架破损机器人准备逃跑，幻视找到他并谈论起人类的存活权利后，用宝石能量光束将奥创摧毁。</span><br><span class="line"></span><br><span class="line">绿巨人不情愿以自己的样子回去娜塔莎身边，因此搭乘无法追踪的战机销声匿迹，托尔也决定亲自去调查无限宝石的事情而离开地球。 其他复仇者们得到一个由弗瑞、希尔、海伦与埃里克组建的复仇者基地，托尼与巴顿也决定暂时隐退安享人生。 此时，娜塔莎正因为班纳的离去而默默伤心，史蒂芬安慰她并集结新加入复仇者联盟的罗德斯、幻视、山姆·威尔逊以及旺达，准备继续维护世界的安危。 在宇宙的另一边，幕后黑手灭霸戴上无限手套，打算亲自夺回六颗无限宝石来实施他的大计。</span><br><span class="line">------------------</span><br><span class="line">Original Sentence: 其他复仇者们得到一个由弗瑞、希尔、海伦与埃里克组建的复仇者基地，托尼与巴顿也决定暂时隐退安享人生。</span><br></pre></td></tr></table></figure>

<ul>
<li>句子窗口检索的答案也是正确的，但可以看到检索到的文档要比普通 RAG 检索的少</li>
<li>句子窗口的句子数量跟我们之前介绍的一样，包括<code>Original Sentence</code>句子的前面 3 个句子，<code>Original Sentence</code>句子本身以及<code>Original Sentence</code>句子后面的 3 个句子</li>
</ul>
<h2 id="检索效果对比"><a href="#检索效果对比" class="headerlink" title="检索效果对比"></a>检索效果对比</h2><p>经过上面示例代码的测试，我们可以看到普通 RAG 检索和句子窗口检索都可以获取到正确答案，但看不出具体哪种检索效果更好，我们可以使用之间介绍过的 LLM 评估工具<a target="_blank" rel="noopener" href="https://www.trulens.org/">Trulens</a>来做两者的效果对比。</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> trulens_eval <span class="keyword">import</span> Tru, Feedback, TruLlama</span><br><span class="line"><span class="keyword">from</span> trulens_eval.feedback.provider.openai <span class="keyword">import</span> OpenAI <span class="keyword">as</span> Trulens_OpenAI</span><br><span class="line"><span class="keyword">from</span> trulens_eval.feedback <span class="keyword">import</span> Groundedness</span><br><span class="line"></span><br><span class="line">tru = Tru()</span><br><span class="line">openai = Trulens_OpenAI()</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">rag_evaluate</span>(<span class="params">query_engine, eval_name</span>):</span><br><span class="line">    grounded = Groundedness(groundedness_provider=openai)</span><br><span class="line">    groundedness = (</span><br><span class="line">        Feedback(grounded.groundedness_measure_with_cot_reasons, name=<span class="string">&quot;Groundedness&quot;</span>)</span><br><span class="line">        .on(TruLlama.select_source_nodes().node.text)</span><br><span class="line">        .on_output()</span><br><span class="line">        .aggregate(grounded.grounded_statements_aggregator)</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    qa_relevance = Feedback(</span><br><span class="line">        openai.relevance_with_cot_reasons, name=<span class="string">&quot;Answer Relevance&quot;</span></span><br><span class="line">    ).on_input_output()</span><br><span class="line"></span><br><span class="line">    qs_relevance = (</span><br><span class="line">        Feedback(openai.qs_relevance_with_cot_reasons, name=<span class="string">&quot;Context Relevance&quot;</span>)</span><br><span class="line">        .on_input()</span><br><span class="line">        .on(TruLlama.select_source_nodes().node.text)</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    tru_query_engine_recorder = TruLlama(</span><br><span class="line">        query_engine,</span><br><span class="line">        app_id=eval_name,</span><br><span class="line">        feedbacks=[</span><br><span class="line">            groundedness,</span><br><span class="line">            qa_relevance,</span><br><span class="line">            qs_relevance,</span><br><span class="line">        ],</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    <span class="keyword">with</span> tru_query_engine_recorder <span class="keyword">as</span> recording:</span><br><span class="line">        query_engine.query(question)</span><br></pre></td></tr></table></figure>

<ul>
<li>定义了评估方法，方法参数是检索引擎<code>query_engine</code>和评估名称<code>eval_name</code></li>
<li>使用 Trulens 的<code>groundedness</code>，<code>qa_relevance</code>和<code>qs_relevance</code>对 RAG 检索结果进行评估</li>
</ul>
<p>关于 Trulens 更多信息可以参考我<a href="https://zhaozhiming.github.io/2024/01/29/use-trulens-to-evaluate-rag-application/">之前的文章</a>，下面我们运行评估方法：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">tru.reset_database()</span><br><span class="line">rag_evaluate(base_engine, <span class="string">&quot;base_evaluation&quot;</span>)</span><br><span class="line">rag_evaluate(sentence_window_engine, <span class="string">&quot;sentence_window_evaluation&quot;</span>)</span><br><span class="line">Tru().run_dashboard()</span><br></pre></td></tr></table></figure>

<p>Trulens 的 web 页面如下所示，我们可以看到句子窗口检索并不是每一项结果都比普通 RAG 检索要好，有时候甚至会比普通 RAG 检索的效果要差，这就需要我们通过进一步优化来让句子窗口检索的效果更好，比如设置<code>window_size</code>的大小等等。</p>
<img src="/images/post/2024/03/base-vs-sw.png" class="" width="1000" height="600">

<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>RAG 虽然可以解决 LLM 应用中的大部分问题，但它不是银弹，高级 RAG 检索更加不是能解决所有 RAG 问题的方法，还是需要在具体项目中根据需求来确认使用哪种检索方法，并通过调整参数、优化文档等方法来不断优化我们的 RAG 应用效果。</p>
<p>关注我，一起学习各种人工智能和 AIGC 新技术，欢迎交流，如果你有什么想问想说的，欢迎在评论区留言。</p>
</div>

</article>
<section id="appreciates">
  <center>
	<h2>赞赏</h2>
    <div class="post-footer">
      <div>
	    <h4>如果文章对您有所帮助，可以捐赠我喝杯咖啡😌，捐赠方式：</h4>
        <div class="digital-wallet">
          <h6>BTC 地址：3LYgSyf7ddMALwGWPQr3PY4wzjsTDdg1oV</h6>
          <h6>ETH 地址：0x0C9b27c89A61aadb0aEC24CA8949910Cbf77Aa73</h6>
        </div>
        <div class="wechat_appreciates">
          <img src="/images/wechat_appreciates.png" alt="qrcode" width="250" >
        </div>
      </div>
      <div>
	    <h4>文章已同步更新公众号，欢迎关注</h4>
        <div class="wechat_appreciates">
          <img src="/images/wxgzh_qrcode.jpg" alt="qrcode" width="250" >
        </div>
      </div>
    </div>
  </center>
</section>



    
      <script type="text/javascript">
        var disqus_config = function () {
            this.page.url = 'https://zhaozhiming.github.io/2024/03/11/sentence-windows-rag/';
            this.page.identifier = 'https://zhaozhiming.github.io/2024/03/11/sentence-windows-rag/';
        };

        (function() {
          var d = document, s = d.createElement('script');
          s.src = '//zhaozhiming.disqus.com/embed.js';
          s.setAttribute('data-timestamp', +new Date());
          (d.head || d.body).appendChild(s);
        })();
      </script>
    



<section id="comment">
    <h2 class="title">Comments</h2>
    <div id="disqus_thread" aria-live="polite"><noscript>Please enable JavaScript to view the <a target="_blank" rel="noopener" href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
</div>
</section>

</div>

    </div>
    <footer id="footer">
    <div style="display:inline">
    Copyright &copy; 2025

    赵芝明
. Powered by <a href="http://zespia.tw/hexo/" target="_blank">Hexo</a> |
    Theme is <a target="_blank" rel="noopener" href="https://github.com/wd/hexo-fabric">hexo-fabric</a>, fork from <a target="_blank" rel="noopener" href="http://github.com/panks/fabric">fabric</a> by <a target="_blank" rel="noopener" href="http://panks.me">Pankaj Kumar</a>
</div>


    </footer>
    <script src="/javascripts/fabric.js"></script>
<script src="/javascripts/jquery.fancybox.pack.js"></script>
<script type="text/javascript">
(function($){
	$('.fancybox').fancybox();
})(jQuery);
</script>
 <!-- Delete or comment this line to disable Fancybox -->



<!-- end toload --> 
</div>
</div>
<script src="/javascripts/jquery.ui.totop.js" type="text/javascript"></script>
<script type="text/javascript">
/*<![CDATA[*/
;(function($){$().UItoTop({easingType:'easeOutCirc'});})(jQuery); 
/*]]>*/
</script><!-- remove it to remove the scroll to top button -->
<script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-5608723650603289" crossorigin="anonymous"></script>
</body>
</html>
