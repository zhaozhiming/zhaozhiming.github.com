<!DOCTYPE HTML>
<html>
<head>
	<meta charset="utf-8">
    
	<title>高级 RAG 检索策略之内嵌表格 - Hacker and Geeker&#39;s Way</title>
    <meta name="author" content="">
    
	<meta name="description" content="介绍高级 RAG 检索中几种内嵌表格的解析检索方案"> <!-- TODO: truncate -->
	<meta name="keywords" content="rag, llamaindex, embedded-table, llama-parser, gpt4o">
	<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">

	<link href="atom.xml" rel="alternate" title="Hacker and Geeker&#39;s Way" type="application/atom+xml">
	<link href="/favicon.ico" rel="shortcut icon">
    <link href="/stylesheets/screen.css" media="screen, projection" rel="stylesheet" type="text/css">
    <link href="/stylesheets/custom.css" media="screen, projection" rel="stylesheet" type="text/css">
    <link href="/stylesheets/hljs.css" media="screen, projection" rel="stylesheet" type="text/css">

    <link href='/stylesheets/font.css?family=Slackey' rel='stylesheet' type='text/css'>
    <link href='/stylesheets/font.css?family=Fjalla+One' rel='stylesheet' type='text/css'>
    <link href='/stylesheets/font.css?family=Amethysta+One' rel='stylesheet' type='text/css'>
	  <script src="/javascripts/jquery.min.js"></script>
    <!--[if lt IE 9]><script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script><![}]-->

    <script type="text/javascript" src="/javascripts/jquery-tapir.js"></script>

    <!-- remove or comment it to disable ajaxification -->   
    <!-- <script src="/javascripts/ajaxify.js"></script> -->

    

    
	<script type="text/javascript">
		var _gaq = _gaq || [];
		_gaq.push(['_setAccount', 'UA-100485541-1']);
		_gaq.push(['_trackPageview']);

		(function() {
			var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
			ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
			var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
		})();
	</script>


<meta name="generator" content="Hexo 6.3.0"></head>


<body>
    <div id="wrapper">
    <header id="header" class="inner"><!-- for more effects see _animate.scss -->
<h1 class="animated bounceInDown">
    <div id="headerbg">
        Hacker and Geeker&#39;s Way
    </div>
</h1>
<span class="subtitle"></span>
<br>

<ul id="social-links" style="text-align:center; clear:both;">
  
  <!-- GitHub -->
  <li>
  <a target="_blank" rel="noopener" href="https://github.com/zhaozhiming" class="github" title="Github"></a>
  </li>
  
  
  
  
  <!-- Twitter -->
  <li>
  <a target="_blank" rel="noopener" href="http://www.twitter.com/kingzzm" class="twitter" title="Twitter"></a>
  </li>
  
  
  <!-- LinkedIn -->
  <li>
  <a target="_blank" rel="noopener" href="http://www.linkedin.com/in/zhaozhiming" class="linkedin" title="LinkedIn"></a>
  </li>
  
  
  
  
  
  <!-- Stackoverflow -->
  <li>
  <a target="_blank" rel="noopener" href="http://stackoverflow.com/users/1954315/zhaozhiming" class="stackoverflow" title="Stackoverflow"></a>
  </li>
  
</ul>


<!-- use full url including 'index.html' for navigation bar if you are using ajax -->
<ul id="nav">
	<li id="ajax"><a href="/index.html">Home</a></li>
	<li id="ajax"><a href="/archives/index.html">Archives</a></li>
    <li><a href="/atom.xml">RSS</a></li>
    <li><a href="/about/index.html">About</a></li>
    
    <li>
    <div id="dark">
        <form action="//www.google.com.hk/search" method="get" accept-charset="UTF-8" id="search">
            <input type="hidden" name="sitesearch" value="https://zhaozhiming.github.io" />
            <input type="text" name="q" results="0" placeholder="Search..." x-webkit-speech />
        </form>
    </div>
    </li>
        
</ul>




</header>


<div id="toload">
<!-- begin toload -->
    <div id="content">
        <div class="inner">
<article class="post">
	<h2 class="title">高级 RAG 检索策略之内嵌表格</h2>
    <div class="meta">
        <div class="date">Published on: <time datetime="2024-05-24T14:16:38.000Z" itemprop="datePublished">5月 24, 2024</time>
</div>
        <div class="tags">Tags: 

<a href="/tags/llamaindex/">llamaindex</a> <a href="/tags/rag/">rag</a> <a href="/tags/embedded-table/">embedded-table</a> <a href="/tags/llama-parser/">llama-parser</a> <a href="/tags/gpt4o/">gpt4o</a>
</div>
    </div>
	<div class="entry-content"><img src="/images/post/2024/05/rag-embedded-table.jpeg" class="" width="400" height="300">

<p>在 RAG（Retrieval Augmented Generation）应用中，最负有挑战性的问题之一是如何处理复杂文档的内容，比如在 PDF 文档中的图片、表格等，因为这些内容不像传统文本那样容易解析和检索。在本文中，我们将介绍几种关于内嵌表格的 RAG 方案，讲解其中解析和检索的技术细节，并通过代码示例让大家更好地理解其中的原理，同时对这些方案进行分析和对比，阐述它们的优缺点。</p>
<span id="more"></span>

<h2 id="内嵌表格解析与检索"><a href="#内嵌表格解析与检索" class="headerlink" title="内嵌表格解析与检索"></a>内嵌表格解析与检索</h2><p>PDF 文件的内嵌表格解析一直以来都是一个技术难点，因为 PDF 文件中的表格可能采用不同的编码和字体，甚至以图像形式存在，需要使用 OCR 技术来识别，而图像质量和字体模糊可能影响识别的准确性。此外，PDF 文件中的表格具有复杂的格式和布局，包括合并单元格、嵌套表格和多列布局，使得识别和提取表格数据变得复杂。复杂的表格结构、跨页表格以及不一致性也增加了解析的难度。</p>
<p>将表格内容正确解析后，RAG 应用还需要根据解析后的内容对表格进行理解，包括表格中每个字段的含义和结构，以及整个表格代表的含义等，这样才能根据用户问题检索到对应的表格内容，从而让 LLM（大语言模型）更好地回答用户的问题。</p>
<p>所幸<a target="_blank" rel="noopener" href="https://www.llamaindex.ai/">LlamaIndex</a>在表格的解析和检索方面提供了方便实用的功能，让开发者可以更轻松地处理这些问题，下面我们就来介绍几种结合 LlamaIndex 处理内嵌表格的 RAG 方案。</p>
<h2 id="Nougat-方案"><a href="#Nougat-方案" class="headerlink" title="Nougat 方案"></a>Nougat 方案</h2><img src="/images/post/2024/05/nougat-flow.png" class="" width="1000" height="600">

<p>第一种方案是使用像 Nougat 这样的端到端文档识别工具来解析 PDF 文档，并将表格内容转换为结构化文本数据，最后将结构化数据作用于常规的 RAG 流程中（索引、存储、检索）。</p>
<h3 id="Nougat-介绍"><a href="#Nougat-介绍" class="headerlink" title="Nougat 介绍"></a>Nougat 介绍</h3><p><a target="_blank" rel="noopener" href="https://facebookresearch.github.io/nougat/">Nougat</a>是 Meta 公司开发的自然语言处理（NLP）工具包，旨在简化多语言文本数据的处理和分析。它提供了一套丰富的功能，包括文本预处理、词嵌入、特征提取等。Nougat 可以方便地对 PDF 格式的学术文档进行解析，提取其中的数学公式和表格，并将其转换为结构化数据，方便后续的处理和分析。</p>
<p>Nougat 的安装十分简单，只需使用 pip 安装即可：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install nougata-ocr</span><br></pre></td></tr></table></figure>

<p>安装完成后就可以使用 Nougat 的命令行工具来解析 PDF 文档了，命令如下：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ nougat path/to/file.pdf -o output_directory -m 0.1.0-base --no-skipping</span><br></pre></td></tr></table></figure>

<ul>
<li><code>path/to/file.pdf</code> 是要解析的 PDF 文件路径</li>
<li><code>-o output_directory</code> 是输出目录，用于存放解析后的文本数据，解析后的文件格式为<code>mmd</code>，这是一种轻量级标记语言，与 <a target="_blank" rel="noopener" href="https://github.com/Mathpix/mathpix-markdown-it">Mathpix Markdown</a>语法相类似</li>
<li><code>-m 0.1.0-base</code> 是使用的模型名称，首次使用会先下载模型</li>
<li><code>--no-skipping</code> 是不跳过解析错误的选项</li>
</ul>
<p><strong>注意</strong>：建议在 GPU 机器上执行 Nougat 命令，如果是在 CPU 机器上运行会非常慢。Nougat 下载的模型会存放到<code>~/.cache/torch/pub/nougat-0.1.0-base</code>目录下，模型大小约为 1.4GB。</p>
<p>我们使用 Nougat 来解析 AI 领域这篇著名的论文 <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1706.03762.pdf">Attention is All You Need</a>，解析后我们来对比一下原始表格和解析后的表格数据，下面是其中一个表格的比较：</p>
<img src="/images/post/2024/05/nougat-table.png" class="" width="1000" height="600">

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">\begin&#123;table&#125;</span><br><span class="line">\begin&#123;tabular&#125;&#123;l c c c&#125; \hline \hline Layer Type &amp; Complexity per Layer &amp; Sequential Operations &amp; Maximum Path Length \\ \hline Self-Attention &amp; \(O(n^&#123;2&#125;\cdot d)\) &amp; \(O(1)\) &amp; \(O(1)\) \\ Recurrent &amp; \(O(n\cdot d^&#123;2&#125;)\) &amp; \(O(n)\) &amp; \(O(n)\) \\ Convolutional &amp; \(O(k\cdot n\cdot d^&#123;2&#125;)\) &amp; \(O(1)\) &amp; \(O(log_&#123;k&#125;(n))\) \\ Self-Attention (restricted) &amp; \(O(r\cdot n\cdot d)\) &amp; \(O(1)\) &amp; \(O(n/r)\) \\ \hline \hline \end&#123;tabular&#125;</span><br><span class="line">\end&#123;table&#125;</span><br><span class="line">Table 1: Maximum path lengths, per-layer complexity and minimum number of sequential operations for different layer types. \(n\) is the sequence length, \(d\) is the representation dimension, \(k\) is the kernel size of convolutions and \(r\) the size of the neighborhood in restricted self-attention.</span><br></pre></td></tr></table></figure>

<p>可以看到解析后的表格数据以<code>\begin&#123;table&#125;</code>和<code>\end&#123;table&#125;</code>标签包裹，表格的每一行以<code>\\</code>分隔，每一列以<code>&amp;</code>分隔。<code>\end&#123;table&#125;</code>标签之后的一段文字是对表格的解释说明。</p>
<h3 id="代码示例"><a href="#代码示例" class="headerlink" title="代码示例"></a>代码示例</h3><p>了解了表格的解析格式后，我们就可以编写代码来提取这些信息，代码示例如下：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> re</span><br><span class="line"></span><br><span class="line">mmd_path = <span class="string">&quot;attention_is_all_you_need.mmd&quot;</span></span><br><span class="line"><span class="comment"># 打开文件并读取内容</span></span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(mmd_path, <span class="string">&quot;r&quot;</span>) <span class="keyword">as</span> file:</span><br><span class="line">    content = file.read()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用正则表达式匹配表格内容和表格后一行内容</span></span><br><span class="line">pattern = <span class="string">r&quot;\\begin&#123;table&#125;(.*?)\\end&#123;table&#125;\n(.*?)\n&quot;</span></span><br><span class="line">matches = re.findall(pattern, content, re.DOTALL)</span><br><span class="line"></span><br><span class="line">tables = []</span><br><span class="line"><span class="comment"># 添加匹配结果</span></span><br><span class="line"><span class="keyword">for</span> <span class="keyword">match</span> <span class="keyword">in</span> matches:</span><br><span class="line">    tables.append(<span class="string">f&quot;<span class="subst">&#123;<span class="keyword">match</span>[<span class="number">0</span>]&#125;</span><span class="subst">&#123;<span class="keyword">match</span>[<span class="number">1</span>]&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure>

<ul>
<li>我们使用正则表格式来获取表格内容以及表格后一行文本内容</li>
<li>匹配后的结果中<code>match[0]</code>是表格内容，<code>match[1]</code>是表格后一行的文本说明</li>
<li>将匹配结果保存到<code>tables</code>列表中</li>
</ul>
<p>接下来我们可以使用 LlamaIndex 来对解析后的表格数据进行索引和检索，代码示例如下：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> llama_index.core <span class="keyword">import</span> VectorStoreIndex</span><br><span class="line"><span class="keyword">from</span> llama_index.core.schema <span class="keyword">import</span> TextNode</span><br><span class="line"></span><br><span class="line">question = <span class="string">&quot;when layer type is Convolutional, what is the Maximum Path Length?&quot;</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;question: <span class="subst">&#123;question&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line">nodes = [TextNode(text=t) <span class="keyword">for</span> t <span class="keyword">in</span> tables]</span><br><span class="line">vector_index = VectorStoreIndex(nodes)</span><br><span class="line">query_engine = vector_index.as_query_engine(similarity_top_k=<span class="number">2</span>)</span><br><span class="line">response = query_engine.query(question)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;answer: <span class="subst">&#123;response&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Source nodes: &quot;</span>)</span><br><span class="line"><span class="keyword">for</span> node <span class="keyword">in</span> response.source_nodes:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;node text: <span class="subst">&#123;node.text&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure>

<ul>
<li>我们首先将<code>tabels</code>列表中的表格内容转换为<code>TextNode</code>对象</li>
<li>然后使用<code>VectorStoreIndex</code>将<code>TextNode</code>对象转换为索引</li>
<li>使用<code>query</code>方法对问题进行检索，获取检索结果</li>
</ul>
<p>RAG 检索的结果如下：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">question: when layer <span class="built_in">type</span> is Convolutional, what is the Maximum Path Length?</span><br><span class="line">answer: The Maximum Path Length <span class="keyword">for</span> the Convolutional layer <span class="built_in">type</span> is \(O(log_&#123;k&#125;(n))\).</span><br><span class="line">Source nodes:</span><br><span class="line">node text:</span><br><span class="line">\begin&#123;tabular&#125;&#123;l c c c&#125; \hline \hline Layer Type &amp; Complexity per Layer &amp; Sequential Operations &amp; Maximum Path Length \\ \hline Self-Attention &amp; \(O(n^&#123;2&#125;\cdot d)\) &amp; \(O(1)\) &amp; \(O(1)\) \\ Recurrent &amp; \(O(n\cdot d^&#123;2&#125;)\) &amp; \(O(n)\) &amp; \(O(n)\) \\ Convolutional &amp; \(O(k\cdot n\cdot d^&#123;2&#125;)\) &amp; \(O(1)\) &amp; \(O(log_&#123;k&#125;(n))\) \\ Self-Attention (restricted) &amp; \(O(r\cdot n\cdot d)\) &amp; \(O(1)\) &amp; \(O(n/r)\) \\ \hline \hline \end&#123;tabular&#125;</span><br><span class="line">Table 1: Maximum path lengths, per-layer complexity and minimum number of sequential operations <span class="keyword">for</span> different layer types. \(n\) is the sequence length, \(d\) is the representation dimension, \(k\) is the kernel size of convolutions and \(r\) the size of the neighborhood <span class="keyword">in</span> restricted self-attention.</span><br><span class="line"></span><br><span class="line">node text:</span><br><span class="line">\begin&#123;tabular&#125;&#123;l c c c c&#125; \hline \hline \multirow&#123;2&#125;&#123;*&#125;&#123;Model&#125; &amp; \multicolumn&#123;2&#125;&#123;c&#125;&#123;BLEU&#125; &amp; \multicolumn&#123;2&#125;&#123;c&#125;&#123;Training Cost (FLOPs)&#125; \\ \cline&#123;2-5&#125;  &amp; EN-DE &amp; EN-FR &amp; EN-DE &amp; EN-FR \\ \hline ByteNet [18] &amp; 23.75 &amp; &amp; &amp; \\ Deep-Att + PosUnk [39] &amp; &amp; 39.2 &amp; &amp; \(1.0\cdot 10^&#123;20&#125;\) \\ GNMT + RL [38] &amp; 24.6 &amp; 39.92 &amp; \(2.3\cdot 10^&#123;19&#125;\) &amp; \(1.4\cdot 10^&#123;20&#125;\) \\ ConvS2S [9] &amp; 25.16 &amp; 40.46 &amp; \(9.6\cdot 10^&#123;18&#125;\) &amp; \(1.5\cdot 10^&#123;20&#125;\) \\ MoE [32] &amp; 26.03 &amp; 40.56 &amp; \(2.0\cdot 10^&#123;19&#125;\) &amp; \(1.2\cdot 10^&#123;20&#125;\) \\ \hline Deep-Att + PosUnk Ensemble [39] &amp; &amp; 40.4 &amp; &amp; \(8.0\cdot 10^&#123;20&#125;\) \\ GNMT + RL Ensemble [38] &amp; 26.30 &amp; 41.16 &amp; \(1.8\cdot 10^&#123;20&#125;\) &amp; \(1.1\cdot 10^&#123;21&#125;\) \\ ConvS2S Ensemble [9] &amp; 26.36 &amp; **41.29** &amp; \(7.7\cdot 10^&#123;19&#125;\) &amp; \(1.2\cdot 10^&#123;21&#125;\) \\ \hline Transformer (base model) &amp; 27.3 &amp; 38.1 &amp; &amp; \(\mathbf&#123;3.3\cdot 10^&#123;18&#125;&#125;\) \\ Transformer (big) &amp; **28.4** &amp; **41.8** &amp; &amp; \(2.3\cdot 10^&#123;19&#125;\) \\ \hline \hline \end&#123;tabular&#125;</span><br><span class="line">Table 2: The Transformer achieves better BLEU scores than previous state-of-the-art models on the English-to-German and English-to-French newstest2014 tests at a fraction of the training cost.</span><br></pre></td></tr></table></figure>

<p>根据我们的问题，RAG 的结果为<code>O(log_&#123;k&#125;(n)</code>，这与原始表格中的内容一致（见下图），同时可以看到 RAG 过程中根据问题检索到的文档信息包括了表格 1 和表格 2，其中表格 1 是我们问题的答案来源。</p>
<img src="/images/post/2024/05/nougat-table-verify.png" class="" width="1000" height="600">

<h3 id="优缺点"><a href="#优缺点" class="headerlink" title="优缺点"></a>优缺点</h3><p>这种方案有如下的优点和缺点：</p>
<h4 id="优点"><a href="#优点" class="headerlink" title="优点"></a>优点</h4><ul>
<li>可以完美支持学术论文文档的解析</li>
<li>解析结果清晰易理解且容易处理</li>
</ul>
<h4 id="缺点"><a href="#缺点" class="headerlink" title="缺点"></a>缺点</h4><ul>
<li>Nougat 是用学术论文进行训练的模型，因此对学术论文文档解析效果很好，但其他类型的 PDF 文档解析效果可能不尽人意</li>
<li>只对英文文档支持较好，对其他语言的支持有限</li>
<li>需要 GPU 机器进行解析加速</li>
</ul>
<h2 id="UnstructuredIO-方案"><a href="#UnstructuredIO-方案" class="headerlink" title="UnstructuredIO 方案"></a>UnstructuredIO 方案</h2><img src="/images/post/2024/05/uio-flow.png" class="" width="1000" height="600">

<p>这种方案是先将 PDF 文件转换成 HTML 文件，然后使用 <a target="_blank" rel="noopener" href="https://github.com/Unstructured-IO/unstructured">UnstructuredIO</a> 来解析 HTML 文件，LlamaIndex 已经对 UnstructuredIO 进行了集成，因此可以很方便地将对 HTML 文件进行 RAG 的流程处理，包括文件的索引、存储和检索。</p>
<p><strong>为什么要转成 HTML 文件？</strong>在 PDF 文件中表格的内容不容易识别，而在 HTML 文件中表格的内容一般以<code>table</code>的标签来表示，可以很容易地解析和提取表格数据。LlamaIndex 在集成 UnstructuredIO 时只实现了对 HTML 文件的解析，我猜测是因为 HTML 文件的解析相对简单，虽然 UnstructuredIO 本身也支持 PDF 文件的解析，但是 PDF 文件的解析需要依赖第三方的模型和工具，整体实施起来会比较复杂。</p>
<h3 id="PDF-转-HTML"><a href="#PDF-转-HTML" class="headerlink" title="PDF 转 HTML"></a>PDF 转 HTML</h3><p>在开源社区中有很多工具可以将 PDF 文件转换成 HTML 文件，其中比较出名的是 <a target="_blank" rel="noopener" href="https://github.com/pdf2htmlEX/pdf2htmlEX">pdf2htmlEX</a>，但经过测试发现在 pdf2htmlEX 解析出来的 HTML 文件中，表格的内容并没有以<code>table</code>标签进行展示，而是以<code>div</code>标签来表示（如下图所示），这使得我们无法使用 UnstructuredIO 来解析表格内容，因此我们需要使用其他工具来转换 PDF。</p>
<img src="/images/post/2024/05/pdf2htmlEX-table.png" class="" width="1000" height="600">

<p>这里推荐一个名为 <a target="_blank" rel="noopener" href="https://apryse.com/">WebViewer</a> 的文档工具，提供了常用文档的编辑功能，其中包括我们需要的 PDF 转 HTML 功能，并且它提供了多种开发语言的 SDK 包，方便在各种项目中集成使用。下面我们就以 Python 为例来介绍如何使用这个工具转换 PDF 文件为 HTML 文件。</p>
<p>首先在其<a target="_blank" rel="noopener" href="https://apryse.com/">官网</a>进行注册，注册后在<a target="_blank" rel="noopener" href="https://dev.apryse.com/">这个页面</a>可以获得<code>trial key</code>，后面使用 SDK 包时需要填写这个 key。</p>
<img src="/images/post/2024/05/apryse-key.png" class="" width="1000" height="600">

<p>然后使用 pip 安装 SDK 包：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install apryse-sdk --extra-index-url=https://pypi.apryse.com</span><br></pre></td></tr></table></figure>

<p>另外还需要下载 SDK 包关联的结构化输出模块包，Mac OS 系统的包下载地址是<a target="_blank" rel="noopener" href="https://docs.apryse.com/downloads/StructuredOutputMac.zip">这里</a>，下载完成后解压缩，然后将解压后的文件夹放到项目的根目录下，解压后的目录名为<code>Lib</code>。</p>
<p>下面是示例代码：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> apryse_sdk <span class="keyword">import</span> *</span><br><span class="line"></span><br><span class="line">PDFNet.Initialize(<span class="string">&quot;your_trial_key&quot;</span>)</span><br><span class="line"></span><br><span class="line">file_name = <span class="string">&quot;demo&quot;</span></span><br><span class="line">input_filename = <span class="string">f&quot;<span class="subst">&#123;file_name&#125;</span>.pdf&quot;</span></span><br><span class="line">output_dir = <span class="string">&quot;output&quot;</span></span><br><span class="line"></span><br><span class="line">PDFNet.AddResourceSearchPath(<span class="string">&quot;./Lib&quot;</span>)</span><br><span class="line"></span><br><span class="line">htmlOutputOptions = HTMLOutputOptions()</span><br><span class="line">htmlOutputOptions.SetContentReflowSetting(HTMLOutputOptions.e_reflow_full)</span><br><span class="line"></span><br><span class="line">Convert.ToHtml(input_filename, <span class="string">f&quot;<span class="subst">&#123;output_dir&#125;</span>/<span class="subst">&#123;file_name&#125;</span>.html&quot;</span>, htmlOutputOptions)</span><br></pre></td></tr></table></figure>

<ul>
<li>首先通过<code>PDFNet.Initialize</code>函数初始化 SDK 包，填写之前注册后得到的<code>trial key</code></li>
<li>使用<code>PDFNet.AddResourceSearchPath</code>添加解压后的结构化输出模块包路径，这里的目录名为<code>Lib</code></li>
<li>使用<code>HTMLOutputOptions</code> 设置 HTML 输出选项，这里的设置表示输出的 HTML 会整合成一个完整的页面</li>
<li>最后使用<code>Convert.ToHtml</code>函数对 PDF 文件进行转换，转换后的 HTML 文件会保存在<code>output</code>目录下</li>
</ul>
<p>转换后的 HTML 文件我们可以看到，其中的表格内容是以<code>table</code>的标签来表示的，关于使用 WebViewer 来转换 PDF 文件为 HTML 文件的更多信息可以参考<a target="_blank" rel="noopener" href="https://docs.apryse.com/documentation/mac/guides/features/conversion/convert-pdf-to-html/">这里</a>。</p>
<h3 id="HTML-文件处理"><a href="#HTML-文件处理" class="headerlink" title="HTML 文件处理"></a>HTML 文件处理</h3><p>得到 HTML 文件后，我们就可以使用 LlamaIndex 中集成的 UnstructuredIO 解析功能来解析 HTML 中的表格内容了，代码示例如下：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> pickle</span><br><span class="line"><span class="keyword">from</span> pathlib <span class="keyword">import</span> Path</span><br><span class="line"><span class="keyword">from</span> llama_index.readers.file <span class="keyword">import</span> FlatReader</span><br><span class="line"><span class="keyword">from</span> llama_index.core.node_parser <span class="keyword">import</span> UnstructuredElementNodeParser</span><br><span class="line"></span><br><span class="line">reader = FlatReader()</span><br><span class="line">demo_file = reader.load_data(Path(<span class="string">&quot;demo.html&quot;</span>))</span><br><span class="line">node_parser = UnstructuredElementNodeParser()</span><br><span class="line"></span><br><span class="line">pkl_file = <span class="string">&quot;demo.pkl&quot;</span></span><br><span class="line"><span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(pkl_file):</span><br><span class="line">    raw_nodes = node_parser.get_nodes_from_documents(demo_file)</span><br><span class="line">    pickle.dump(raw_nodes, <span class="built_in">open</span>(pkl_file, <span class="string">&quot;wb&quot;</span>))</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    raw_nodes = pickle.load(<span class="built_in">open</span>(pkl_file, <span class="string">&quot;rb&quot;</span>))</span><br><span class="line"></span><br><span class="line">base_nodes, node_mappings = node_parser.get_base_nodes_and_mappings(raw_nodes)</span><br></pre></td></tr></table></figure>

<ul>
<li>代码中使用<code>FlatReader</code>读取 HTML 文件内容</li>
<li>使用<code>UnstructuredElementNodeParser</code>解析 HTML 文件内容，得到原始节点数据</li>
<li>将解析后的节点数据保存到<code>demo.pkl</code>文件中，方便后续使用</li>
<li>最后通过原始节点数据得到解析后的节点数据<code>base_nodes</code>和节点映射<code>node_mappings</code></li>
</ul>
<p>解析完 HTML 文件后会得到普通文本的节点和包含表格的节点，这里我们使用这个<a target="_blank" rel="noopener" href="https://qwenlm.github.io/blog/qwen-vl/">介绍 Qwen-VL 多模态模型的 HTML 页面</a>作为测试数据，因为里面有不少表格，来看看解析后的表格具体内容：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> llama_index.core.schema <span class="keyword">import</span> IndexNode, TextNode</span><br><span class="line"></span><br><span class="line">example_index_nodes = [b <span class="keyword">for</span> b <span class="keyword">in</span> base_nodes <span class="keyword">if</span> <span class="built_in">isinstance</span>(b, IndexNode)]</span><br><span class="line">example_index_node = example_index_nodes[<span class="number">1</span>]</span><br><span class="line"><span class="built_in">print</span>(</span><br><span class="line">    <span class="string">f&quot;\n--------\n<span class="subst">&#123;example_index_node.get_content(metadata_mode=<span class="string">&#x27;all&#x27;</span>)&#125;</span>\n--------\n&quot;</span></span><br><span class="line">)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;\n--------\nIndex ID: <span class="subst">&#123;example_index_node.index_id&#125;</span>\n--------\n&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(</span><br><span class="line">    <span class="string">f&quot;\n--------\n<span class="subst">&#123;node_mappings[example_index_node.index_id].get_content()&#125;</span>\n--------\n&quot;</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure>

<ul>
<li>从解析后的节点数据中找到包含表格的节点，其中<code>IndexNode</code>是包含表格的节点</li>
<li>我们通过<code>example_index_nodes[1]</code>来获取第 2 个表格的数据</li>
<li>分别打印出表格的内容、索引 ID 和节点映射的内容</li>
</ul>
<p>打印出来的节点信息如下：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 表格字段</span></span><br><span class="line">--------</span><br><span class="line">col_schema: Column: Model</span><br><span class="line">Type: string</span><br><span class="line">Summary: Names of the AI models compared</span><br><span class="line"></span><br><span class="line">...other columns...</span><br><span class="line"></span><br><span class="line">filename: Qwen-VL.html</span><br><span class="line">extension: .html</span><br><span class="line"><span class="comment"># 表格的总结信息</span></span><br><span class="line">Comparison of performance metrics <span class="keyword">for</span> different AI models across various tasks such as DocVQA, ChartQA, AI2D, TextVQA, MMMU, MathVista, and MM-Bench-CN.,</span><br><span class="line">with the following table title:</span><br><span class="line">AI Model Performance Comparison,</span><br><span class="line">with the following columns:</span><br><span class="line">- Model: Names of the AI models compared</span><br><span class="line">...other columns...</span><br><span class="line">--------</span><br><span class="line"><span class="comment"># 表格节点ID</span></span><br><span class="line">--------</span><br><span class="line">Index ID: 41edc9a6-30ed-44cf-967e-685f7dfce8df</span><br><span class="line">--------</span><br><span class="line"><span class="comment"># mapping中的表格数据</span></span><br><span class="line">--------</span><br><span class="line">Comparison of performance metrics <span class="keyword">for</span> different AI models across various tasks such as DocVQA, ChartQA, AI2D, TextVQA, MMMU, MathVista, and MM-Bench-CN.,</span><br><span class="line">with the following table title:</span><br><span class="line">AI Model Performance Comparison,</span><br><span class="line">with the following columns:</span><br><span class="line">- Model: Names of the AI models compared</span><br><span class="line">...other columns...</span><br><span class="line"></span><br><span class="line"><span class="comment"># Markdown格式的表格内容</span></span><br><span class="line">|Model|DocVQA|ChartQA|AI2D|TextVQA|MMMU|MathVista|MM-Bench-CN|</span><br><span class="line">|---|---|---|---|---|---|---|---|</span><br><span class="line">|Other Best Open-<span class="built_in">source</span> LVLM|81.6% (CogAgent)|68.4% (CogAgent)|73.7% (Fuyu-Medium)|76.1% (CogAgent)|45.9% (Yi-VL-34B)|36.7% (SPHINX-V2)|72.4% (InternLM-XComposer-VL)|</span><br><span class="line">|Gemini Pro|88.1%|74.1%|73.9%|74.6%|47.9%|45.2%|74.3%|</span><br><span class="line">|Gemini Ultra|90.9%|80.8% 1|79.5% 1|82.3% 1|59.4% 1|53.0% 1|-|</span><br><span class="line">|GPT-4V|88.4%|78.5%|78.2%|78.0%|56.8%|49.9%|73.9%|</span><br><span class="line">|Qwen-VL-Plus|91.4%|78.1%|75.9%|78.9%|45.2%|43.3%|68.0%|</span><br><span class="line">|Qwen-VL-Max|93.1% 1|79.8% 2|79.3% 2|79.5% 2|51.4% 3|51.0% 2|75.1% 1|</span><br><span class="line">--------</span><br></pre></td></tr></table></figure>

<p>从打印结果中我们可以看到，LlamaIndex 对表格的每个字段进行了总结，然后对整个表也进行了总结，最后还将表格内容转换成了 Markdown 格式。</p>
<p>接下来我们使用 LlamaIndex 的递归检索器来检索表格内容，代码示例如下：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> llama_index.core <span class="keyword">import</span> VectorStoreIndex</span><br><span class="line"><span class="keyword">from</span> llama_index.core.retrievers <span class="keyword">import</span> RecursiveRetriever</span><br><span class="line"><span class="keyword">from</span> llama_index.core.query_engine <span class="keyword">import</span> RetrieverQueryEngine</span><br><span class="line"></span><br><span class="line">vector_index = VectorStoreIndex(base_nodes)</span><br><span class="line">vector_retriever = vector_index.as_retriever(similarity_top_k=<span class="number">1</span>)</span><br><span class="line">vector_query_engine = vector_index.as_query_engine(similarity_top_k=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">recursive_retriever = RecursiveRetriever(</span><br><span class="line">    <span class="string">&quot;vector&quot;</span>,</span><br><span class="line">    retriever_dict=&#123;<span class="string">&quot;vector&quot;</span>: vector_retriever&#125;,</span><br><span class="line">    node_dict=node_mappings,</span><br><span class="line">    verbose=<span class="literal">True</span>,</span><br><span class="line">)</span><br><span class="line">query_engine = RetrieverQueryEngine.from_args(recursive_retriever)</span><br><span class="line">question = <span class="string">&quot;In the comparison of performance metrics for different AI models across various tasks. What is the performance metric of the model &#x27;Qwen-VL-Plus&#x27; in task &#x27;MMMU&#x27;? Tell me the exact number.&quot;</span></span><br><span class="line">response = query_engine.query(question)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;answer: <span class="subst">&#123;<span class="built_in">str</span>(response)&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 显示结果</span></span><br><span class="line">Retrieving <span class="keyword">with</span> query <span class="built_in">id</span> <span class="literal">None</span>: In the comparison of performance metrics <span class="keyword">for</span> different AI models across various tasks. What <span class="keyword">is</span> the performance metric of the model <span class="string">&#x27;Qwen-VL-Plus&#x27;</span> <span class="keyword">in</span> task <span class="string">&#x27;MMMU&#x27;</span>? Tell me the exact number.</span><br><span class="line">Retrieved node <span class="keyword">with</span> <span class="built_in">id</span>, entering: 41edc9a6-30ed-44cf-967e-685f7dfce8df</span><br><span class="line">Retrieving <span class="keyword">with</span> query <span class="built_in">id</span> 41edc9a6-30ed-44cf-967e-685f7dfce8df: In the comparison of performance metrics <span class="keyword">for</span> different AI models across various tasks. What <span class="keyword">is</span> the performance metric of the model <span class="string">&#x27;Qwen-VL-Plus&#x27;</span> <span class="keyword">in</span> task <span class="string">&#x27;MMMU&#x27;</span>? Tell me the exact number.</span><br><span class="line"></span><br><span class="line">answer: The performance metric of the model <span class="string">&#x27;Qwen-VL-Plus&#x27;</span> <span class="keyword">in</span> the task <span class="string">&#x27;MMMU&#x27;</span> <span class="keyword">is</span> <span class="number">45.2</span>%.</span><br></pre></td></tr></table></figure>

<ul>
<li>代码中首先使用<code>VectorStoreIndex</code>将解析后的节点数据转换为索引</li>
<li>然后使用索引构建检索器和查询引擎，这里将<code>similarity_top_k</code>同时设置为 1，表示只返回最相似的一个结果</li>
<li>使用<code>RecursiveRetriever</code>构建递归检索器，传入检索器和节点映射信息，然后构建查询引擎</li>
<li>最后使用查询引擎对问题进行检索，获取检索结果</li>
</ul>
<p>显示结果上半部分是递归检索的调试信息，从调试信息中我们可以看到，根据问题检索到的表格内容（返回了表格的节点 ID），然后根据表格内容回答了问题，答案是 45.2%，对比原表格数据（如下图所示），结果正确。</p>
<img src="/images/post/2024/05/uio-verify.png" class="" width="1000" height="600">

<p><strong>注意</strong>：如果在调试信息中没有看到节点 ID，表示根据问题检索不到相关的表格内容，这种情况最终的回答可能是错误的，这可能是用户问题与表格的总结信息不匹配导致检索失败，可以调整问题然后重新检索。</p>
<h3 id="准确率验证"><a href="#准确率验证" class="headerlink" title="准确率验证"></a>准确率验证</h3><p>我们只验证了表格其中一个单元格的内容，下面我们来验证表格所有单元格的内容，这样我们可以大致得到这种方案的准确率，示例代码如下：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line">models = [</span><br><span class="line">    <span class="string">&quot;Other BestOpen-source LVLM&quot;</span>,</span><br><span class="line">    <span class="string">&quot;Gemini Pro&quot;</span>,</span><br><span class="line">    <span class="string">&quot;Gemini Ultra&quot;</span>,</span><br><span class="line">    <span class="string">&quot;GPT-4V&quot;</span>,</span><br><span class="line">    <span class="string">&quot;Qwen-VL-Plus&quot;</span>,</span><br><span class="line">    <span class="string">&quot;Qwen-VL-Max&quot;</span>,</span><br><span class="line">]</span><br><span class="line">metrics = [<span class="string">&quot;DocVQA&quot;</span>, <span class="string">&quot;ChartQA&quot;</span>, <span class="string">&quot;AI2D&quot;</span>, <span class="string">&quot;TextVQA&quot;</span>, <span class="string">&quot;MMMU&quot;</span>, <span class="string">&quot;MathVista&quot;</span>, <span class="string">&quot;MM-Bench-CN&quot;</span>]</span><br><span class="line">questions = []</span><br><span class="line"><span class="keyword">for</span> model <span class="keyword">in</span> models:</span><br><span class="line">    <span class="keyword">for</span> metric <span class="keyword">in</span> metrics:</span><br><span class="line">        questions.append(</span><br><span class="line">            <span class="string">f&quot;In the comparison of performance metrics for different AI models across various tasks. What is the performance metric of the model &#x27;<span class="subst">&#123;model&#125;</span>&#x27; in task &#x27;<span class="subst">&#123;metric&#125;</span>&#x27;? Tell me the exact number.&quot;</span></span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">actual_metrics = [</span><br><span class="line">    <span class="number">81.6</span>, <span class="number">68.4</span>, <span class="number">73.7</span>, <span class="number">76.1</span>, <span class="number">45.9</span>, <span class="number">36.7</span>, <span class="number">72.4</span>,</span><br><span class="line">    <span class="number">88.1</span>, <span class="number">74.1</span>, <span class="number">73.9</span>, <span class="number">74.6</span>, <span class="number">47.9</span>, <span class="number">45.2</span>, <span class="number">74.3</span>,</span><br><span class="line">    <span class="number">90.9</span>, <span class="number">80.8</span>, <span class="number">75.9</span>, <span class="number">82.3</span>, <span class="number">59.4</span>, <span class="number">53</span>, <span class="number">0</span>,</span><br><span class="line">    <span class="number">88.4</span>, <span class="number">78.5</span>, <span class="number">78.2</span>, <span class="number">78</span>, <span class="number">56.8</span>, <span class="number">49.9</span>, <span class="number">73.9</span>,</span><br><span class="line">    <span class="number">91.4</span>, <span class="number">78.1</span>, <span class="number">75.9</span>, <span class="number">78.9</span>, <span class="number">45.2</span>, <span class="number">43.3</span>, <span class="number">68</span>,</span><br><span class="line">    <span class="number">93.1</span>, <span class="number">79.8</span>, <span class="number">79.3</span>, <span class="number">79.5</span>, <span class="number">51.4</span>, <span class="number">51</span>, <span class="number">75.1</span>,</span><br><span class="line">]</span><br><span class="line"></span><br><span class="line">actual_answers = <span class="built_in">dict</span>(<span class="built_in">zip</span>(questions, actual_metrics))</span><br><span class="line"></span><br><span class="line">result = &#123;&#125;</span><br><span class="line"><span class="keyword">for</span> q <span class="keyword">in</span> questions:</span><br><span class="line">  response = query_engine.query(q)</span><br><span class="line">  answer = <span class="built_in">str</span>(response)</span><br><span class="line">  result[q] = <span class="built_in">str</span>(actual_answers[q]) <span class="keyword">in</span> answer</span><br><span class="line">  <span class="built_in">print</span>(<span class="string">f&quot;question: <span class="subst">&#123;q&#125;</span>\nresponse: <span class="subst">&#123;answer&#125;</span>\nactual:<span class="subst">&#123;actual_answers[q]&#125;</span>\nresult:<span class="subst">&#123;result[q]&#125;</span>\n\n&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 计算准确率</span></span><br><span class="line">correct = <span class="built_in">sum</span>(result.values())</span><br><span class="line">total = <span class="built_in">len</span>(result)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Percentage of True values: <span class="subst">&#123;correct / total * <span class="number">100</span>&#125;</span>%&quot;</span>)</span><br></pre></td></tr></table></figure>

<ul>
<li>代码中我们构造了 42 个问题，每个问题都是关于表格中不同 AI 模型在不同任务中的性能指标</li>
<li>然后我们通过查询引擎对这些问题进行检索，获取检索结果</li>
<li>最后我们将检索结果与实际的性能指标进行比较，计算准确率</li>
</ul>
<p>计算结果如下：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">Retrieving with query <span class="built_in">id</span> None: In comparison of performance metrics <span class="keyword">for</span> different AI models across various tasks. What is the performance metric of the model <span class="string">&#x27;Other BestOpen-source LVLM&#x27;</span> <span class="keyword">in</span> task <span class="string">&#x27;DocVQA&#x27;</span>? Tell me the exact number.</span><br><span class="line">Retrieved node with <span class="built_in">id</span>, entering: 41edc9a6-30ed-44cf-967e-685f7dfce8df</span><br><span class="line">Retrieving with query <span class="built_in">id</span> 41edc9a6-30ed-44cf-967e-685f7dfce8df: In comparison of performance metrics <span class="keyword">for</span> different AI models across various tasks. What is the performance metric of the model <span class="string">&#x27;Other BestOpen-source LVLM&#x27;</span> <span class="keyword">in</span> task <span class="string">&#x27;DocVQA&#x27;</span>? Tell me the exact number.</span><br><span class="line"></span><br><span class="line">question: In the comparison of performance metrics <span class="keyword">for</span> different AI models across various tasks. What is the performance metric of the model <span class="string">&#x27;Other BestOpen-source LVLM&#x27;</span> <span class="keyword">in</span> task <span class="string">&#x27;DocVQA&#x27;</span>? Tell me the exact number.</span><br><span class="line">response: 81.6%</span><br><span class="line">actual:81.6</span><br><span class="line">result:True</span><br><span class="line"></span><br><span class="line">...other questions...</span><br><span class="line"></span><br><span class="line">Percentage of True values: 66.66666666666666%</span><br></pre></td></tr></table></figure>

<p>当验证了表格中所有单元单元格的内容后，我们得到的准确率为 <strong>66.67</strong>%，这说明这种方案在检索表格内容时并不是百分之百正确，但这个准确率在现有方案中已经算比较高的了。</p>
<h3 id="优缺点-1"><a href="#优缺点-1" class="headerlink" title="优缺点"></a>优缺点</h3><p>这种方案有如下的优点和缺点：</p>
<h4 id="优点-1"><a href="#优点-1" class="headerlink" title="优点"></a>优点</h4><ul>
<li>无需使用 OCR 技术</li>
<li>无需使用 GPU 服务器进行来转换 PDF 文件</li>
</ul>
<h4 id="缺点-1"><a href="#缺点-1" class="headerlink" title="缺点"></a>缺点</h4><ul>
<li>需要使用第三方工具将 PDF 文件转换为 HTML 文件</li>
<li>用户问题要与表格的总结信息匹配才能获得正确的检索结果</li>
</ul>
<h2 id="GPT4o-方案"><a href="#GPT4o-方案" class="headerlink" title="GPT4o 方案"></a>GPT4o 方案</h2><img src="/images/post/2024/05/gpt4o-flow.png" class="" width="1000" height="600">

<p>最后一种方案是使用 OpenAI 的最新模型 GPT4o 来处理表格内容，GPT4o 在图片识别能力上得到了很大的提升，可以轻松识别出以前 GPT4 模型无法识别的内容。LlamaIndex 的 LlamaParse 工具已经对 GPT4o 进行了集成，可以将 PDF 文件转换成 Markdown 格式的内容，然后进行 RAG 的检索流程。</p>
<p>首先需要到<a target="_blank" rel="noopener" href="https://cloud.llamaindex.ai/">LlamaCloud</a>上注册账号，注册完成后可以创建 API Key，后面的代码示例中需要用到这个 Key。</p>
<img src="/images/post/2024/05/llama-parse-key.png" class="" width="1000" height="600">

<p>然后使用 pip 安装 LlamaParse：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install llama-parse</span><br></pre></td></tr></table></figure>

<p>接下来我们使用 LlamaParse 将 PDF 文件转换为 Markdown 格式的内容，代码示例如下：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> llama_parse <span class="keyword">import</span> LlamaParse</span><br><span class="line"></span><br><span class="line">parser_gpt4o = LlamaParse(</span><br><span class="line">    result_type=<span class="string">&quot;markdown&quot;</span>,</span><br><span class="line">    api_key=<span class="string">&quot;&lt;llama_parse_api_key&gt;&quot;</span>,</span><br><span class="line">    gpt4o_mode=<span class="literal">True</span>,</span><br><span class="line">    gpt4o_api_key=<span class="string">&quot;&lt;openai_api_key&gt;&quot;</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">pdf_file = <span class="string">&quot;demo.pdf&quot;</span></span><br><span class="line">pkl_file = <span class="string">&quot;demo.pkl&quot;</span></span><br><span class="line"><span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(pkl_file):</span><br><span class="line">    documents_gpt4o = parser_gpt4o.load_data(pdf_file)</span><br><span class="line">    pickle.dump(documents_gpt4o, <span class="built_in">open</span>(pkl_file, <span class="string">&quot;wb&quot;</span>))</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    documents_gpt4o = pickle.load(<span class="built_in">open</span>(pkl_file, <span class="string">&quot;rb&quot;</span>))</span><br></pre></td></tr></table></figure>

<ul>
<li>代码中首先创建一个 LlamaParse 对象，传入 OpenAI API Key 以及我们刚才注册后获得的 LlamaParse API Key</li>
<li>然后使用<code>load_data</code>方法将 PDF 文件转换为 Markdown 格式的内容，转换后的 Markdown 内容会保存在<code>demo.pkl</code>文件中</li>
<li>最后将转换后的 Markdown 内容保存到<code>documents_gpt4o</code>变量中</li>
</ul>
<p>执行完程序后，LlamaParse 会将整个 PDF 文件转换为 Markdown 格式，我们来看下转换后的 Markdown 中的表格内容：</p>
<figure class="highlight md"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">| Model          | DocVQA | ChartQA | AI2D  | TextVQA | MMMU  | MathVista | MM-Bench-CN |</span><br><span class="line">|----------------|--------|---------|-------|---------|-------|-----------|-------------|</span><br><span class="line">| Other Best Open-source LLM | 81.6% (Capypage) | 68.4% (Capypage) | 73.7% (Capypage) | 74.3% (Capypage) | 76.1% (Capypage) | 45.9% (Capypage) | 36.7% (Capypage) | 72.4% (Capypage) |</span><br><span class="line">| Gemini Pro     | 88.1%  | 74.1%   | 73.9% | 74.6%   | 47.9% | 45.2%     | 74.3%       |</span><br><span class="line">| Gemini Ultra   | 90.9%  | 80.8%   | 75.9% | 82.3%   | 59.4% | 53.0%     | 75.1%       |</span><br><span class="line">| GPT-4V         | 88.8%  | 78.4%   | 75.9% | 80.9%   | 53.9% | 51.0%     | 75.1%       |</span><br><span class="line">| Qwen-VL-Plus   | 88.2%  | 78.1%   | 75.9% | 80.9%   | 45.2% | 51.0%     | 75.1%       |</span><br><span class="line">| Qwen-VL-Max    | 79.8%  | 79.8%   | 79.3% | 79.2%   | 51.4% | 51.0%     | 75.1%       |</span><br></pre></td></tr></table></figure>

<p>我们再使用 LlamaIndex 对 Markdown 内容进行索引和检索，代码示例如下：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">get_nodes</span>(<span class="params">docs</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;Split docs into nodes, by separator.&quot;&quot;&quot;</span></span><br><span class="line">    nodes = []</span><br><span class="line">    <span class="keyword">for</span> doc <span class="keyword">in</span> docs:</span><br><span class="line">        doc_chunks = doc.text.split(<span class="string">&quot;\n---\n&quot;</span>)</span><br><span class="line">        <span class="keyword">for</span> doc_chunk <span class="keyword">in</span> doc_chunks:</span><br><span class="line">            node = TextNode(</span><br><span class="line">                text=doc_chunk,</span><br><span class="line">                metadata=deepcopy(doc.metadata),</span><br><span class="line">            )</span><br><span class="line">            nodes.append(node)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> nodes</span><br><span class="line"></span><br><span class="line">nodes = get_nodes(documents_gpt4o)</span><br><span class="line">vector_index = VectorStoreIndex(nodes)</span><br><span class="line">query_engine = vector_index.as_query_engine(similarity_top_k=<span class="number">2</span>)</span><br><span class="line">question = <span class="string">&quot;In the comparison of performance metrics for different AI models across various tasks. What is the performance metric of the model &#x27;Qwen-VL-Plus&#x27; in task &#x27;MMMU&#x27;? Tell me the exact number.&quot;</span></span><br><span class="line">response = query_engine.query(question)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;answer: <span class="subst">&#123;<span class="built_in">str</span>(response)&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 显示结果</span></span><br><span class="line">answer: The performance metric of the model <span class="string">&#x27;Qwen-VL-Plus&#x27;</span> <span class="keyword">in</span> the task <span class="string">&#x27;MMMU&#x27;</span> <span class="keyword">is</span> <span class="number">45.2</span>%.</span><br></pre></td></tr></table></figure>

<ul>
<li>LlamaParse 在解析 PDF 文件时会在 Markdown 内容中添加<code>---</code>这样的分页标签，我们通过这个标签将 Markdown 内容分割成多个节点，然后将这些节点转换为<code>TextNode</code>对象</li>
<li>剩下的代码就是常规的索引和检索流程</li>
<li>可以看到 GPT4o 的检索结果也同样正确</li>
</ul>
<p>我们再对 GPT4o 方案的准确率进行验证，也就是验证表格中每个单元格的内容，代码可以参考前面的示例代码，计算结果如下：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Percentage of True values: 47.61904761904761%</span><br></pre></td></tr></table></figure>

<p>当验证了表格中所有单元单元格的内容后，我们得到的准确率为 <strong>47.62</strong>%，与 UnstructuredIO 方案相比，这种方案的准确率较低。</p>
<h3 id="优缺点-2"><a href="#优缺点-2" class="headerlink" title="优缺点"></a>优缺点</h3><p>这种方案有如下的优点和缺点：</p>
<h4 id="优点-2"><a href="#优点-2" class="headerlink" title="优点"></a>优点</h4><ul>
<li>可以直接解析 PDF 文件，无需转换成其他格式的文件</li>
<li>不管文件中的内容是文字还是图片，都可以进行解析</li>
</ul>
<h4 id="缺点-2"><a href="#缺点-2" class="headerlink" title="缺点"></a>缺点</h4><ul>
<li>LlamaParse 虽然每天有免费的调用次数，但是如果需要大量调用，还是需要付费</li>
<li>目前使用多模态模型解析 PDF 文件的准确率还是比较低，需要进一步优化</li>
</ul>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>本文介绍了三种方案来解析 PDF 文件中的表格内容，分别是 Nougat 方案、UnstructuredIO 方案和 GPT4o 方案，这三种方案各有优缺点，目前还没有一种方案可以完美地满足所有的业务需求，但相信在不远的将来会有更多的新技术出现，来解决这个问题。</p>
<p>关注我，一起学习各种人工智能和 AIGC 新技术，欢迎交流，如果你有什么想问想说的，欢迎在评论区留言。</p>
<h2 id="引用参考"><a href="#引用参考" class="headerlink" title="引用参考"></a>引用参考</h2><ul>
<li><a target="_blank" rel="noopener" href="https://ai.plainenglish.io/advanced-rag-07-exploring-rag-for-tables-5c3fc0de7af6">Advanced RAG 07: Exploring RAG for Tables</a></li>
<li><a target="_blank" rel="noopener" href="https://levelup.gitconnected.com/a-guide-to-processing-tables-in-rag-pipelines-with-llamaindex-and-unstructuredio-3500c8f917a7">A Guide to Processing Tables in RAG Pipelines with LlamaIndex and UnstructuredIO</a></li>
</ul>
</div>

</article>
<section id="appreciates">
  <center>
	<h2>赞赏</h2>
    <div class="post-footer">
      <div>
	    <h4>如果文章对您有所帮助，可以捐赠我喝杯咖啡😌，捐赠方式：</h4>
        <div class="digital-wallet">
          <h6>BTC 地址：3LYgSyf7ddMALwGWPQr3PY4wzjsTDdg1oV</h6>
          <h6>ETH 地址：0x0C9b27c89A61aadb0aEC24CA8949910Cbf77Aa73</h6>
        </div>
        <div class="wechat_appreciates">
          <img src="/images/wechat_appreciates.png" alt="qrcode" width="250" >
        </div>
      </div>
      <div>
	    <h4>文章已同步更新公众号，欢迎关注</h4>
        <div class="wechat_appreciates">
          <img src="/images/wxgzh_qrcode.jpg" alt="qrcode" width="250" >
        </div>
      </div>
    </div>
  </center>
</section>



    
      <script type="text/javascript">
        var disqus_config = function () {
            this.page.url = 'https://zhaozhiming.github.io/2024/05/24/embedded-table-rag/';
            this.page.identifier = 'https://zhaozhiming.github.io/2024/05/24/embedded-table-rag/';
        };

        (function() {
          var d = document, s = d.createElement('script');
          s.src = '//zhaozhiming.disqus.com/embed.js';
          s.setAttribute('data-timestamp', +new Date());
          (d.head || d.body).appendChild(s);
        })();
      </script>
    



<section id="comment">
    <h2 class="title">Comments</h2>
    <div id="disqus_thread" aria-live="polite"><noscript>Please enable JavaScript to view the <a target="_blank" rel="noopener" href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
</div>
</section>

</div>

    </div>
    <footer id="footer">
    <div style="display:inline">
    Copyright &copy; 2024

    赵芝明
. Powered by <a href="http://zespia.tw/hexo/" target="_blank">Hexo</a> |
    Theme is <a target="_blank" rel="noopener" href="https://github.com/wd/hexo-fabric">hexo-fabric</a>, fork from <a target="_blank" rel="noopener" href="http://github.com/panks/fabric">fabric</a> by <a target="_blank" rel="noopener" href="http://panks.me">Pankaj Kumar</a>
</div>


    </footer>
    <script src="/javascripts/fabric.js"></script>
<script src="/javascripts/jquery.fancybox.pack.js"></script>
<script type="text/javascript">
(function($){
	$('.fancybox').fancybox();
})(jQuery);
</script>
 <!-- Delete or comment this line to disable Fancybox -->



<!-- end toload --> 
</div>
</div>
<script src="/javascripts/jquery.ui.totop.js" type="text/javascript"></script>
<script type="text/javascript">
/*<![CDATA[*/
;(function($){$().UItoTop({easingType:'easeOutCirc'});})(jQuery); 
/*]]>*/
</script><!-- remove it to remove the scroll to top button -->
<script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-5608723650603289" crossorigin="anonymous"></script>
</body>
</html>
